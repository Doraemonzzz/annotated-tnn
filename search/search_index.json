{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Home This blog contains a detailed explanation of Tnn , and we provide both Chinese and English versions.","title":"Home"},{"location":"#home","text":"This blog contains a detailed explanation of Tnn , and we provide both Chinese and English versions.","title":"Home"},{"location":"en/","text":"","title":"En"},{"location":"zh/","text":"The Annotated Tnn Toeplitz Neural Network for Sequence Modeling \u535a\u5ba2\u7531 Doreamonzzz \u64b0\u5199\u3002 \u66f4\u65b0\u65e5\u5fd7\uff1a - 20230313\uff0c\u5f00\u59cb\u64b0\u5199\u535a\u5ba2\uff1b - 20230320\uff0c\u5b8c\u6210\u52a8\u673a\u4ee5\u53ca\u5404\u4e2a\u90e8\u4ef6\u7684\u5b9e\u73b0\u90e8\u5206\uff1b - 20230524\uff0c\u5b8c\u6210\u6821\u9605\u4ee5\u53ca\u5f15\u7528\uff1b Toeplitz Neural Network(TNN)\u662f\u4e00\u79cd\u5168\u65b0\u7684\u7f51\u7edc\u7ed3\u6784\uff0c\u4ee5\u4e00\u79cd\u5b8c\u5168\u4e0d\u540c\u7684\u65b9\u5f0f\u8fdb\u884c\u5e8f\u5217\u5efa\u6a21\uff0c\u5728\u5355\u5411/\u53cc\u5411\u8bed\u8a00\u6a21\u578b\uff0c\u56fe\u50cf\u5206\u7c7b\u4efb\u52a1\u4e0a\u548cTransformer\u6027\u80fd\u76f8\u8fd1\uff0c\u5e76\u4e14\u5728\u957f\u5e8f\u5217\u5efa\u6a21 LRA \u4efb\u52a1\u4e0a\u53d6\u5f97\u548c S4 \u76f8\u5f53\u7684\u6027\u80fd\u3002\u8fd9\u7bc7\u535a\u5ba2\u7684\u4e3b\u8981\u76ee\u7684\u5c31\u662f\u4ee5 The Annotated Transformer \u548c The Annotated S4 \u98ce\u683c\u4ecb\u7ecdTNN\uff0c\u5728\u9605\u8bfb\u5b8c\u8fd9\u7bc7\u535a\u5ba2\u540e\uff0c\u60a8\u5c06\u5f97\u5230\u5982\u4e0b\u6536\u83b7\uff1a 1. \u4e86\u89e3TNN\u7684\u52a8\u673a\u548c\u8bbe\u8ba1\u7406\u5ff5\uff1b 2. \u638c\u63e1TNN\u5404\u4e2a\u90e8\u4ef6\u7684\u5b9e\u73b0\uff1b \u603b\u800c\u8a00\u4e4b\uff0c\u5728\u9605\u8bfb\u5b8c\u672c\u535a\u5ba2\u4e4b\u540e\uff0c\u60a8\u5c06\u6210\u4e3aTNN\u7684\u4e13\u5bb6\uff0c\u5e76\u4e14\u53ef\u4ee5\u5c06TNN\u5e94\u7528\u5230\u60a8\u7684\u9879\u76ee\u4e2d\uff0c\u8ba9\u6211\u4eec\u5f00\u59cb\u5427\u3002 \u76ee\u5f55 \u76ee\u5f55 \u9884\u5907\u77e5\u8bc6 Token mixing and channel mixing \u76f8\u5bf9\u4f4d\u7f6e\u7f16\u7801 TNN\u7684\u52a8\u673a TNN\u7684\u5b9e\u73b0 \u51c6\u5907\u5de5\u4f5c Tno\u7684\u5b9e\u73b0 Naive\u5b9e\u73b0 Matrix production\u5b9e\u73b0 FFT\u5b9e\u73b0 Circulant matrix \u5b9a\u4e49 \u5feb\u901f\u77e9\u9635\u4e58\u6cd5 \u5b9e\u73b0 \u5c0f\u7ed3 Toeplitz matrix \u5b9a\u4e49 \u5feb\u901f\u77e9\u9635\u4e58\u6cd5 \u5b9e\u73b0 \u9a8c\u8bc1\u5b9e\u73b0 \u8865\u5145 \u5c0f\u7ed3 Rpe\u7684\u5b9e\u73b0 Naive\u5b9e\u73b0 Relative Position Encoder \u5b9e\u73b0Relative Position Encoder \u5c06Tno\u548cRpe\u5408\u5e76 Tnn layer\u7684\u5b9e\u73b0 GLU GTU TnnLayer \u5c0f\u7ed3 \u5168\u6587\u603b\u7ed3 \u9884\u5907\u77e5\u8bc6 Token mixing and channel mixing \u8ba9\u6211\u4eec\u9996\u5148\u4eceTransformer\u5f00\u59cb\u3002Transformer\u4f5c\u4e3a\u4e00\u4e2a\u7f51\u7edc\u7ed3\u6784\u5df2\u7ecf\u5e2d\u5377\u4e86\u5404\u4e2a\u9886\u57df\uff0c\u5176\u6838\u5fc3\u90e8\u5206\u4e3b\u8981\u53ef\u4ee5\u7531\u5982\u4e0b\u4e24\u4e2a\u8ba1\u7b97\u516c\u5f0f\u63cf\u8ff0\uff1a $$ \\begin{aligned} \\mathbf X_1 &=\\mathrm{Norm}(\\mathbf X + \\mathrm{MHA}(\\mathbf X)),\\ \\mathbf O &= \\mathrm{Norm}(\\mathbf X_1 + \\mathrm{FFN}(\\mathbf X_1)). \\end{aligned} $$ \u5176\u4e2d$\\mathbf X \\in \\mathbb R^{n\\times d}$\u662f\u8f93\u5165\uff08\u4e5f\u53ef\u4ee5\u79f0\u4e3atoken matrix\uff0c\u5176\u4e2d\u77e9\u9635\u7684\u6bcf\u4e00\u884c\u4e3a\u4e00\u4e2atoken\u7684\u5411\u91cf\u8868\u793a\uff09\uff0c$n$\u662f\u5e8f\u5217\u957f\u5ea6\uff0c$d$\u662f\u7279\u5f81\u7ef4\u5ea6\u3002 \u65e2\u7136\u73b0\u5728\u6709\u4e24\u4e2a\u4e3b\u8981\u6a21\u5757\u2014\u2014$\\mathrm {MHA}$\u548c$\\mathrm {FFN}$\uff0c\u90a3\u4e48\u4ed6\u4eec\u7684\u4f5c\u7528\u662f\u5426\u6709\u6240\u4e0d\u540c\u5462\uff1f\u5728 Metaformer \u4e00\u6587\u4e2d\uff0c\u7814\u7a76\u8005\u6307\u51fa\uff0c$\\mathrm {MHA}$\u7684\u4e3b\u8981\u4f5c\u7528\u662fToken mixing\uff0c\u800c$\\mathrm {FFN}$\u7684\u4e3b\u8981\u4f5c\u7528\u662fChannel mixing\u3002 \u8fd9\u662f\u4ec0\u4e48\u610f\u601d\u5462\uff1f\u6211\u4eec\u53ef\u4ee5\u4ece\u77e9\u9635\u4e58\u6cd5\u7684\u89d2\u5ea6\u6e05\u6670\u7684\u7406\u89e3\u8fd9\u70b9\uff1a\u7ed9\u5b9a\u8f93\u5165\uff08token matrix\uff09$\\mathbf X \\in \\mathbb R^{n\\times d}$\uff0c\u8003\u8651\u77e9\u9635\u4e58\u6cd5$\\mathbf A \\mathbf X$\u548c$\\mathbf X \\mathbf B$\uff0c\u90a3\u4e48\uff1a - $\\mathbf A \\mathbf X$\u8868\u793a\u77e9\u9635$\\mathbf X$\u884c\u7684\u7ebf\u6027\u7ec4\u5408\uff0c\u800c\u6bcf\u4e00\u884c\u8868\u793a\u4e00\u4e2atoken\uff0c\u5373token\u7684\u7ebf\u6027\u7ec4\u5408\uff0c\u6240\u4ee5\u79f0\u4e3atoken mixing\uff1b - $\\mathbf X \\mathbf B$\u8868\u793a\u77e9\u9635$\\mathbf X$\u5217\u7684\u7ebf\u6027\u7ec4\u5408\uff0c\u800c\u6bcf\u4e00\u5217\u8868\u793a\u4e00\u4e2achannel\uff0c\u5373channel\u7684\u7ebf\u6027\u7ec4\u5408\uff0c\u6240\u4ee5\u79f0\u4e3achannel mixing\uff1b \u5728Transformer\u4e2d\uff0c\u77e9\u9635$\\mathbf A$\u5373\u4e3a$\\mathrm{Softmax}(\\mathbf Q \\mathbf K^{\\top} /\\sqrt{d})$\uff0c\u77e9\u9635$\\mathbf B$\u5373\u4e3a$\\mathrm {FFN}$\u4e2d\u7684\u5168\u8fde\u63a5\u5c42\u3002 \u5927\u591a\u6570\u5bf9Transformer\u7684\u6539\u8fdb\u90fd\u662f\u96c6\u4e2d\u5728token mixing:$\\mathbf A \\mathbf X$\u7684\u8ba1\u7b97\u4e0a\uff0c\u4ee5\u5404\u79cd\u5404\u6837\u7684\u65b9\u5f0f\u964d\u4f4e\u5176\u8fd0\u7b97\u590d\u6742\u5ea6\uff0cTNN\u4e5f\u662f\u4f7f\u7528\u4e86\u7c7b\u4f3c\u7684\u601d\u8def\uff0c\u6700\u6838\u5fc3\u7684\u4e00\u70b9\u5c31\u662f\u5229\u7528\u4e86\u76f8\u5bf9\u4f4d\u7f6e\u7f16\u7801\uff0c\u6216\u8005\u8bf4\uff0cToeplitz\u77e9\u9635\u3002 \u76f8\u5bf9\u4f4d\u7f6e\u7f16\u7801 \u4f4d\u7f6e\u7f16\u7801\u662fTransformer\u4e2d\u7684\u91cd\u8981\u7ec4\u6210\u90e8\u5206\uff0c\u4e00\u5f00\u59cb\u5e7f\u4e3a\u4f7f\u7528\u7684\u662f \u7edd\u5bf9\u4f4d\u7f6e\u7f16\u7801(APE) \uff0c\u8fd9\u79cd\u7f16\u7801\u7684\u65b9\u5f0f\u53ef\u4ee5\u7528\u5982\u4e0b\u8ba1\u7b97\u65b9\u5f0f\u6982\u62ec\uff1a $$ \\mathbf x_i =\\mathbf w_i + \\mathbf p_i. $$ \u5176\u4e2d$\\mathbf w_i$\u8868\u793a\u7b2c$i$\u4e2a\u8bcd\u7684word embedding\uff0c$\\mathbf p_i$\u8868\u793a\u7b2c$i$\u4e2a\u4f4d\u7f6e\u7684position embedding\u3002 \u540e\u6765\uff0c\u6709\u7814\u7a76\u4eba\u5458\u53d1\u73b0\uff0c\u5728\u5e8f\u5217\u5efa\u6a21\u4e2d\uff0c\u8bcd\u7684\u76f8\u5bf9\u4f4d\u7f6e\u4fe1\u606f\uff0c\u53ef\u80fd\u6bd4\u8bcd\u7684\u7edd\u4f4d\u7f6e\u4fe1\u606f\u66f4\u52a0\u91cd\u8981\u3002 \u4f8b\u5982\"\u6211\u5e74\u7eaa\u6bd4\u4f60\u5927\"\u7684\u8bed\u610f\u548c\"\u6211\u5e74\u7eaa\u6bd4\u4f60\u5927\"\u5b8c\u5168\u4e0d\u540c\uff0c\u4f46\u662f\u8fd9\u4e24\u53e5\u8bdd\u53ea\u662f\u4ea4\u6362\u4e86\"\u4f60\"\u548c\"\u6211\"\u7684\u4f4d\u7f6e\u3002 \u4e8e\u662f\u7814\u7a76\u4eba\u5458\u5f00\u59cb\u5c06\u76f8\u5bf9\u4f4d\u7f6e\u7f16\u7801\u5f15\u5165\uff0c\u76f8\u5bf9\u4f4d\u7f6e\u7f16\u7801\u7684\u4f7f\u7528\u548c\u7edd\u5bf9\u4f4d\u7f6e\u7f16\u7801\u6709\u6240\u4e0d\u540c\uff0c\u5176\u4f5c\u7528\u5728Attention\u8ba1\u7b97\u7684\u4f4d\u7f6e\uff1a $$ \\mathbf s_{ij} = \\mathbf q_i^{\\top} \\mathbf k_j/\\sqrt{d} + t_{i-j}. $$ \u5982\u679c\u5199\u6210\u77e9\u9635\u7684\u5f62\u5f0f\u5219\u66f4\u52a0\u76f4\u89c2\uff1a $$ \\begin{aligned} \\mathbf S & = \\mathbf Q \\mathbf K^{\\top} / \\sqrt {d} + \\mathbf T,\\ \\mathbf T & =\\left[\\begin{matrix} t_0 & t_{-1} & \\cdots & t_{-n+1} \\ t_1 & t_0 & & \\vdots \\ \\vdots & & t_0 & t_{-1} \\ t_{n-1} & \\ldots & t_1 & t_0 \\end{matrix}\\right] \\in \\mathbb R^{n\\times n}. \\end{aligned} $$ \u8fd9\u91cc\uff0c\u77e9\u9635$\\mathbf T$\u6709\u4e00\u4e2a\u6570\u5b66\u540d\u79f0\u2014\u2014 Toeplitz\u77e9\u9635 \uff0c\u4e0d\u96be\u770b\u51fa\u8be5\u77e9\u9635\u6709$2n-1$\u4e2a\u72ec\u7acb\u5143\u7d20\u3002 TNN\u7684\u52a8\u673a \u6709\u4e86\u4e4b\u524d\u7684\u51c6\u5907\u5de5\u4f5c\uff0c\u53ef\u4ee5\u5f15\u5165\u6211\u4eec\u5de5\u4f5c\u7684\u4e24\u4e2a\u52a8\u673a\uff1a 1. \u65e2\u7136\u76f8\u5bf9\u4f4d\u7f6e\u4fe1\u606f\u5982\u6b64\u91cd\u8981\uff0c\u90a3\u4e48\u6709\u6ca1\u6709\u53ef\u80fd\u53ea\u4f9d\u8d56\u4e8e\u76f8\u5bf9\u4f4d\u7f6e\u4fe1\u606f\uff08Toeplitz matrix\uff09\u8fdb\u884ctoken mixing\u5462\uff1f 1. \u76f4\u89c2\u4e0a\u6765\u8bf4\uff0c\u5c31\u662f\u5c06Attention Matrix\u66ff\u6362\u4e3aToeplitz matrix\u3002 2. \u5047\u8bbe(1)\u6210\u7acb\uff0c\u90a3\u4e48\u6211\u4eec\u9700\u8981\u8fdb\u884c\u7684\u4e3b\u8981\u64cd\u4f5c\u662f$\\mathbf T \\mathbf X$\uff0c\u65e2\u7136\u77e9\u9635$\\mathbf T$\u662f\u4e00\u4e2a\u7279\u6b8a\u7ed3\u6784\u7684\u77e9\u9635\uff0c\u90a3\u4e48\u6709\u6ca1\u6709\u53ef\u80fd\u52a0\u901f\u8fd0\u7b97\u5462\uff1f \u6211\u4eec\u5bf9\u4e24\u4e2a\u95ee\u9898\u90fd\u8fdb\u884c\u4e86\u80af\u5b9a\u7684\u7b54\u590d\uff1a 1. \u5b8c\u5168\u53ef\u4ee5\u53ea\u4f9d\u8d56\u4e8e\u76f8\u5bf9\u4f4d\u7f6e\u4fe1\u606f\u8fdb\u884ctoken mixing\uff1b 2. \u7531\u4e8e\u77e9\u9635\u7684\u7279\u6b8a\u6027\uff0c\u53ef\u4ee5\u5c06\u8fd0\u7b97\u590d\u6742\u5ea6\u7531$O(n^2 d)$\u964d\u4f4e\u4e3a$O(nd\\log n)$\uff1b \u53ef\u4ee5\u770b\u5230\uff0c\u6211\u4eec\u7684\u52a8\u673a\u6781\u5176\u7b80\u5355\u548c\u4f18\u96c5\uff0c\u6700\u6838\u5fc3\u7684\u601d\u8def\u5c31\u662f\u5c06$\\mathrm{Softmax}(\\mathbf Q \\mathbf K^{\\top} / \\sqrt {d})$\u66ff\u6362\u4e3a$\\mathbf T$\uff0c\u4f46\u662f\uff0c\u8fd9\u79cd\u7b80\u5355\u7684\u66ff\u6362\u5c31\u53ef\u4ee5\u62e5\u6709\u6bd4\u5404\u79cd\u82b1\u54e8\u66f4\u6539\u66f4\u597d\u7684\u6027\u80fd\uff0c\u8fd9\u5c31\u66f4\u52a0\u9a8c\u8bc1\u4e86\u76f8\u5bf9\u4f4d\u7f6e\u4fe1\u606f\u5728\u5e8f\u5217\u5efa\u6a21\u4e2d\u7684\u91cd\u8981\u6027\u3002 TNN\u7684\u5b9e\u73b0 \u51c6\u5907\u5de5\u4f5c \u63a5\u4e0b\u6765\u7684\u95ee\u9898\u5c31\u662f\u5982\u4f55\u5b9e\u73b0TNN\uff0c\u5728\u6b64\u4e4b\u524d\uff0c\u6211\u4eec\u5bf9\u4e4b\u524d\u7684\u516c\u5f0f\u505a\u4e00\u5b9a\u7684\u8c03\u6574\u3002 \u5728\u4e4b\u524d\u7684\u8ba8\u8bba\u4e2d\uff0c\u6211\u4eec\u63d0\u5230\u4e86$\\mathbf T \\mathbf X$\u53ef\u4ee5\u9ad8\u6548\u5b9e\u73b0\uff0c\u5176\u4e2d$\\mathbf T\\in \\mathbb R^{n\\times n}, \\mathbf X \\in \\mathbb R^{n\\times d}$\uff0c\u8fd9\u79cd\u60c5\u51b5\u76f8\u5f53\u4e8e\u6bcf\u4e2achannel\u5171\u4eab\u540c\u4e00\u4e2aToeplitz matrix\uff0c\u4f46\u662f\u6ce8\u610f\u5230\u6211\u4eec\u53ef\u4ee5\u8ba9\u4e0d\u540c\u7684channel\u4f7f\u7528\u4e0d\u540c\u7684Toeplitz matrix\uff0c\u6211\u4eec\u7ecf\u9a8c\u4e0a\u53d1\u73b0\uff0c\u8fd9\u6837\u4e00\u5b9a\u7a0b\u5ea6\u4e0a\u53ef\u4ee5\u589e\u5927\u6a21\u578b\u7684\u8868\u8fbe\u6027\uff0c\u6240\u4ee5\u5728TNN\u4e2d\uff0c \u6bcf\u4e2achannel \u4f7f\u7528\u4e86\u4e0d\u540c\u7684Toeplitz matrix\u3002\u6ce8\u610f\u5230\u5f62\u72b6\u4e3a$n\\times n$\u7684Toeplitz matrix\u5b9e\u9645\u4e0a\u53ea\u6709$2n-1$\u4e2a\u72ec\u7acb\u5143\u7d20\uff0c\u4e3a\u4e86\u65b9\u4fbf\u540e\u7eed\u8ba8\u8bba\uff0c\u6211\u4eec\u5b9a\u4e49\u5982\u4e0b\u6620\u5c04\uff1a$f: \\mathbb R^{(2n-1)\\times 1} \\to \\mathbb R^{n\\times n}$\uff1a $$ f(\\mathbf t)=f(t_{-n+1},\\ldots, t_{n-1}) =\\left[\\begin{matrix} t_0 & t_{-1} & \\cdots & t_{-n+1} \\ t_1 & t_0 & & \\vdots \\ \\vdots & & t_0 & t_{-1} \\ t_{n-1} & \\ldots & t_1 & t_0 \\end{matrix}\\right] \\in \\mathbb R^{n\\times n}. $$ \u8be5\u6620\u5c04\u7684\u4f5c\u7528\u662f\u5c06\u7ef4\u5ea6\u4e3a$(2n-1)\\times 1$\u7684\u5411\u91cf\u586b\u5145\u4e3a$n\\times n$\u7684Toeplitz matrix\u3002 \u7ed3\u5408\u4e4b\u524d\u7684\u8bb0\u53f7\uff0c\u6211\u4eec\u5b9a\u4e49\u4e3aTno\u7b97\u5b50(Toeplitz neural operator)\u4e3a\uff1a $$ \\mathrm{Tno}: \\mathbb R^{(2n-1)\\times d}\\times \\mathbb R^{n\\times d} \\to \\mathbb R^{n\\times d},\\ \\mathbf O= \\mathrm{Tno}(\\mathbf T, \\mathbf X), \\ \\mathbf O[:, i]= f(\\mathbf T[:, i]) \\mathbf X[:, i]. $$ \u5907\u6ce8\uff1a\u8fd9\u91cc\u7684\u8bb0\u53f7$\\mathbf T\\in \\mathbb R^{(2n-1)\\times d}$\u548c\u4e00\u5f00\u59cb\u542b\u4e49\u6709\u6240\u4e0d\u540c\uff0c\u6ce8\u610f\u4e0d\u8981\u641e\u6df7\u3002 \u5728\u5f00\u59cb\u6b63\u5f0f\u7684\u5b9e\u73b0\u4e4b\u524d\uff0c\u6211\u4eec\u5148\u5f15\u5165\u4e00\u4e9b\u5fc5\u8981\u7684\u4f9d\u8d56\u5e93\u4ee5\u53ca\u4e00\u4e9b\u8f85\u52a9\u51fd\u6570\uff1a import torch import torch.nn as nn import torch.nn.functional as F from einops import rearrange def get_activation_fn(activation): if activation == \"gelu\": return F.gelu elif activation == \"relu\": return F.relu elif activation == \"elu\": return F.elu elif activation == \"sigmoid\": return F.sigmoid elif activation == \"exp\": return torch.exp elif activation == \"leak\": return F.leaky_relu elif activation == \"1+elu\": def f(x): return 1 + F.elu(x) return f elif activation == \"2+elu\": def f(x): return 2 + F.elu(x) return f elif activation == \"silu\": return F.silu else: return lambda x: x Tno\u7684\u5b9e\u73b0 Naive\u5b9e\u73b0 \u6700\u6734\u7d20\u7684\u5b9e\u73b0\u81ea\u7136\u662f\u5229\u7528\u5b9a\u4e49\u8fdb\u884c\u5b9e\u73b0\uff0c\u4f8b\u5982\u5982\u4e0b\u4ee3\u7801\u4e2d\uff0c\u6211\u4eec\u4f7f\u75284\u91cd\u5faa\u73af\uff0c\u5916\u9762\u4e24\u91cd\u5faa\u73af\u904d\u5386batch, channel\u7ef4\u5ea6\uff0c\u7b2c\u4e09\u91cd\u5faa\u73af\u904d\u5386\u8f93\u51fa\u4f4d\u7f6e\uff0c\u6700\u540e\u4e00\u91cd\u5faa\u73af\u904d\u5386\u6c42\u548c\u9879\uff0c\u6ce8\u610f\u5230\u6211\u4eec\u7684$\\mathbf T[:, i]$\u8f93\u5165\u5f62\u5f0f\u4e3a$t_{-n+1}, ... , t_{-1}, t_0, t_1, ... , t_{n - 1}$\uff0c\u7b2c\u4e09\u91cd\u5faa\u73af\u904d\u5386\u5230$i$\u65f6\uff0c\u6d89\u53ca\u7684$t$\u4e3a$t_{i}, t_{i-1},\\ldots, t_{i-n+1}$\uff0c\u800c$n - 1 + i$\u662f$t_{i}$\u5728$\\mathbf T[:, i]$\u7684\u5b9e\u9645\u7d22\u5f15\uff1a def tno_naive(x, t): # x: (b, n, d) # t: (2n - 1, d), t_(-(n - 1)), ... , t_(-1), t_0, t_1, ... , t_(n - 1) b, n, d = x.shape o = torch.zeros_like(x).to(x) for b_ in range(b): for d_ in range(d): for i in range(n): for j in range(n): o[b_][i][d_] += t[n - 1 + i - j][d_] * x[b_][j][d_] return o \u8fd9\u79cd\u5b9e\u73b0\u663e\u7136\u592a\u4f4e\u6548\uff0c\u4f46\u662f\u81f3\u5c11\u6211\u4eec\u6709\u4e86\u4e00\u4e2a\u6b63\u786e\u7684\u7248\u672c\uff0c\u8fd9\u5bf9\u6211\u4eec\u540e\u7eed\u6539\u8fdb\u7b97\u6cd5\u4e5f\u662f\u6709\u5e2e\u52a9\u7684\uff0c\u4e0d\u96be\u770b\u51fa\u8fd9\u6837\u8ba1\u7b97\u7684\u65f6\u95f4\u590d\u6742\u5ea6\u4e3a$O(n^2d)$\uff0c\u7a7a\u95f4\u590d\u6742\u5ea6\u4e3a$O(nd)$\uff08\u5ffd\u7565batch\u7ef4\u5ea6\uff09\u3002 Matrix production\u5b9e\u73b0 \u7b2c\u4e8c\u79cd\u5b9e\u73b0\u662f\u5e76\u884c\u7248\u672c\uff0c\u5176\u601d\u8def\u5c31\u662f\u5148\u6784\u9020Toeplitz matrix\uff0c\u7136\u540e\u5229\u7528\u77e9\u9635\u4e58\u6cd5\u8fdb\u884c\u8ba1\u7b97\u3002\u6700\u4e3b\u8981\u7684\u90e8\u5206\u662f\u5c06\u6620\u5c04$f$\u5b9e\u73b0\u51fa\u6765\uff0c\u4ee3\u7801\u57fa\u4e8e \u6b64\u5904 \uff0c\u4e3b\u8981\u601d\u8def\u662f\u5148\u5c06\u8f93\u5165\u6539\u5199\u4e3a$t_0, t_{-1}, ... , t_{1-n}, t_{n - 1}, ... , t_1$\uff0c\u7136\u540e\u6784\u9020index $0, 1, \\ldots,n -1, -(n - 1), ..., -1$\uff0c\u5c06\u8f93\u5165\u6620\u5c04\u5230Toeplitz matrix\uff0c\u6700\u540e\u5f97\u5230Toeplitz matrix\u8fdb\u884c\u77e9\u9635\u4e58\u6cd5\uff1a def tno_matrix(x, t): # x: (b, n, d) # t: (2n - 1, d), t_(-(n - 1)), ... , t_(-1), t_0, t_1, ... , t_(n - 1) n = x.shape[1] t = t.unsqueeze(0) # c: t_0, t_1, ... , t_(n - 1) c = t[:, n - 1:] # r: t_0, t_(-1), ... , t_(-(n - 1)) r = t[:, :n].flip(1) # vals: [t_0, t_(-1), ... , t_(-(n - 1)), t_(n - 1), ... , t_1] vals = torch.cat([r, c[:, 1:].flip(1)], dim=-2) i, j = torch.ones(n, n).nonzero().T t_matrix = vals[:, j - i].reshape(n, n, -1) o = torch.einsum(\"n m d, b m d -> b n d\", t_matrix, x) return o \u8fd9\u79cd\u5b9e\u73b0\u7684\u597d\u5904\u662f\u53ef\u4ee5\u5229\u7528\u77e9\u9635\u4e58\u6cd5\uff0c\u5c3d\u7ba1\u590d\u6742\u5ea6\u4f9d\u7136\u4e3a$O(n^2d)$\uff0c\u4f46\u5b9e\u9645\u6548\u7387\u4f1a\u5feb\u5f88\u591a\uff1b\u4f46\u662f\u7531\u4e8e\u8981\u6784\u9020Toeplitz matrix\uff0c\u6240\u4ee5\u7a7a\u95f4\u590d\u6742\u5ea6\u4e3a$O(n^2d)$\uff0c\u5e76\u4e14\u8fd9\u90e8\u5206\u8fd8\u662f\u4e00\u4e2a\u5f88\u5927\u7684IO\u5f00\u9500\uff0c\u6240\u4ee5\u5b9e\u9645\u4e2d\u7684\u901f\u5ea6\u5e76\u4e0d\u4f1a\u5f88\u5feb\u3002 FFT\u5b9e\u73b0 \u6709\u4e86\u4e4b\u524d\u7684\u94fa\u57ab\uff0c\u53ef\u4ee5\u770b\u51fa\u524d\u4e24\u79cd\u65b9\u6cd5\u65e0\u8bba\u662f\u65f6\u95f4\u590d\u6742\u5ea6\u548c\u7a7a\u95f4\u590d\u6742\u5ea6\u76f8\u6bd4Attention\u5e76\u6ca1\u6709\u4ec0\u4e48\u4f18\u52bf\uff0c\u90a3\u4e48\u6709\u6ca1\u6709\u529e\u6cd5\u89e3\u51b3\u8fd9\u70b9\u5462\uff1f\u56de\u7b54\u662f\u80af\u5b9a\u7684\uff0c\u8fd9\u5c31\u9700\u8981 FFT \u8fd9\u628a\u5229\u5203\u3002\u540e\u7eed\u7684\u8ba8\u8bba\u6d89\u53ca\u5230\u4e00\u4e9b\u6570\u5b66\u77e5\u8bc6\uff0c\u8fd9\u91cc\u5148\u9ad8\u5ea6\u6982\u62ec\u4e00\u4e0b\u601d\u8def\uff1a 1. \u7ed9\u51faCirculant matrix\u7684\u5feb\u901f\u77e9\u9635\u4e58\u6cd5\u7b97\u6cd5\uff1b 2. \u5efa\u7acbToeplitz marix\u548cCirculant matrix\u7684\u5173\u7cfb\uff1b Circulant matrix \u5b9a\u4e49 \u77e9\u9635$\\mathbf C\\in \\mathbb R^{n\\times n}$\u662f\u4e00\u4e2a Circulant matrix \u5f53\u4e14\u4ec5\u5f53$\\mathbf C_{ij}= c_{(i-j + n )\\bmod n}$ ,\u5373\uff1a $$ \\mathbf C=\\left[\\begin{matrix} c_0 & c_{n-1} &c_{n-2} & \\cdots & \\cdots & c_{1} \\ c_1 & c_0 & c_{n-1} & \\ddots & & \\vdots \\ c_2 & c_1 & \\ddots & \\ddots & \\ddots & \\vdots \\ \\vdots & \\ddots & \\ddots & \\ddots & c_{n-1} & c_{n-2} \\ \\vdots & & \\ddots & c_1 & c_0 & c_{n-1} \\ c_{n-1} & \\ldots & \\ldots & c_2 & c_1 & c_0 \\end{matrix}\\right] \\in \\mathbb R^{n\\times n}. $$ \u5173\u4e8eCirculant matrix\uff0c\u6709\u5982\u4e0b\u91cd\u8981\u6027\u8d28\uff1a Circulant matrix $\\mathbf C\\in \\mathbb R^{n\\times n}$\u6b63\u4ea4\u76f8\u4f3c\u4e8e\u5bf9\u89d2\u9635$\\mathbf \\Lambda$\uff0c\u7279\u522b\u5730\uff0c\u76f8\u4f3c\u77e9\u9635$\\mathbf F$\u662f$n\\times n$ DFT\u77e9\u9635: $$ \\mathbf C = \\mathbf F^{\\top} \\Lambda \\mathbf F, \\ \\Lambda = \\mathrm{diag}{\\mathbf F[c_0,c_1,\\ldots, c_{n-1}]^\\top} \\in \\mathbb R^{n\\times n}, {\\mathbf F}_{st}= \\exp\\left(\\frac{2\\pi st i}{n}\\right),i^2=-1. $$ \u8bc1\u660e\u53ef\u4ee5\u53c2\u8003 \u8fd9\u91cc \u3002 \u5feb\u901f\u77e9\u9635\u4e58\u6cd5 \u73b0\u5728\u8003\u8651matrix-vector production\u64cd\u4f5c$\\mathbf M \\mathbf x, \\mathbf M\\in \\mathbb R^{n\\times n}, \\mathbf x\\in \\mathbb R^{n\\times 1}$\uff0c\u90a3\u4e48\uff1a \u5982\u679c$\\mathbf M$\u4e3a\u4e00\u822c\u7684\u77e9\u9635\uff0c\u90a3\u4e48\u8be5\u8ba1\u7b97\u7684\u65f6\u95f4\u590d\u6742\u5ea6\u4e3a$O(n^2)$; \u5982\u679c$\\mathbf M$\u4e3aDFT\u77e9\u9635\uff0c\u90a3\u4e48\u8be5\u8ba1\u7b97\u7684\u65f6\u95f4\u590d\u6742\u5ea6\u4e3a$O(n \\log n)$; \u57fa\u4e8e\u4e0a\u8ff0\u4e8b\u5b9e\uff0c\u8003\u8651$\\mathbf M=\\mathbf C$\u4e3aCirculant matrix\u7684\u60c5\u5f62\uff0c\u90a3\u4e48\uff1a $$ \\mathbf C \\mathbf x = \\mathbf F^{\\top} \\Lambda \\mathbf F \\mathbf x. $$ \u8be5\u8ba1\u7b97\u53ef\u4ee5\u5206\u89e3\u4e3a\u51e0\u4e2a\u6b65\u9aa4\uff1a $\\mathbf x_{\\mathrm{fft}}=\\mathbf{Fx}$\uff1b $\\mathbf c_{\\mathrm{fft}}=\\mathbf F[c_0,c_1,\\ldots, c_{n-1}]^\\top$\uff1b $\\mathbf o_{\\mathrm{fft}}=\\mathbf x_{\\mathrm{fft}}\\odot \\mathbf c_{\\mathrm{fft}}$\uff1b $\\mathbf o= \\mathbf F^{\\top} \\mathbf o_{\\mathrm{fft}}$\uff1b \u5176\u4e2d$\\odot$\u8868\u793aelement-wise production\uff0c\u53ef\u4ee5\u770b\u51fa\uff0c\u7b97\u6cd5\u7684\u603b\u65f6\u95f4\u590d\u6742\u5ea6\u4e3a$O(n\\log n)$\uff0c\u7a7a\u95f4\u590d\u6742\u5ea6\u4e3a$O(n)$\uff0c\u6240\u4ee5Circulant matrix\u5bf9\u5e94\u7684\u77e9\u9635\u4e58\u6cd5\u662f\u9ad8\u6548\u7684\u3002 \u5b9e\u73b0 \u6709\u4e86\u4e4b\u524d\u7684\u8bf4\u660e\uff0c\u4e0d\u96be\u5229\u7528 fft \u5b9e\u73b0\u4e0a\u8ff0\u8ba1\u7b97\uff1a def circulant_fft(x, c): # x: (b, n, d) # c: (n, d), c_0, c_1, ... , c_(n - 1) n = x.shape[1] c = c.unsqueeze(0) x_fft = torch.fft.rfft(x, n, dim=-2) c_fft = torch.fft.rfft(c, n, dim=-2) o_fft = x_fft * c_fft o = torch.fft.irfft(o_fft, n, dim=-2) return o \u5c0f\u7ed3 \u73b0\u5728\u6211\u4eec\u5df2\u7ecf\u6709\u4e86\u4e00\u4e2a\u5173\u4e8eCirculant matrix\u7684\u9ad8\u6548\u77e9\u9635\u4e58\u6cd5\uff0c\u90a3\u4e48\u4e0b\u4e00\u4e2a\u95ee\u9898\u5c31\u662f\u5efa\u7acbToeplitz matrix\u548cCirculant matrix\u7684\u5173\u7cfb\u3002 Toeplitz matrix \u5b9a\u4e49 \u77e9\u9635$\\mathbf T\\in \\mathbb R^{n\\times n}$\u662f\u4e00\u4e2aToeplitz matrix\u5f53\u4e14\u4ec5\u5f53$\\mathbf T_{ij}= t_{i-j}$\uff0c\u5373 $$ \\mathbf T=\\left[\\begin{matrix} t_0 & t_{-1} &t_{-2} & \\cdots & \\cdots & t_{-n+1} \\ t_1 & t_0 & t_{-1} & \\ddots & & \\vdots \\ t_2 & t_1 & \\ddots & \\ddots & \\ddots & \\vdots \\ \\vdots & \\ddots & \\ddots & \\ddots & t_{-1} & t_{n-2} \\ \\vdots & & \\ddots & t_1 & t_0 & t_{-1} \\ t_{n-1} & \\ldots & \\ldots & t_2 & t_1 & t_0 \\end{matrix}\\right] \\in \\mathbb R^{n\\times n}. $$ \u4ece\u5f62\u5f0f\u4e0a\u6765\u770b\uff0cToeplitz matrix\u548cCirculant matrix\u975e\u5e38\u50cf\uff0c\u552f\u4e00\u7684\u533a\u522b\u5728\u4e8e\u524d\u8005\u7684\u72ec\u7acb\u5143\u7d20\u6570\u91cf\u4e3a$2n-1$\uff0c\u540e\u8005\u7684\u72ec\u7acb\u5143\u7d20\u6570\u91cf\u4e3a$n$\uff0c\u90a3\u4e48\u4e00\u4e2a\u7b80\u5355\u7684\u601d\u8def\u5c31\u662f\u5c06Toeplitz matrix\u5d4c\u5165\u5230\u4e00\u4e2a\u9636\u6570\u5927\u4e8e\u7b49\u4e8e$2n-1$\u77e9\u9635\u4e2d\uff0c\u800c\u8fd9\u4e2a\u77e9\u9635\u672c\u751f\u662f\u4e00\u4e2aCirculant matrix\uff0c\u4e0b\u9762\u6765\u770b\u4e0b\u8fd9\u662f\u5982\u4f55\u5177\u4f53\u64cd\u4f5c\u7684\u3002 \u53ef\u4ee5\u5c06Toeplitz matrix $\\mathbf T\\in \\mathbb R^{n\\times }$\u5d4c\u5165\u5230Circulant matrix $\\mathbf C \\in \\mathbb R^{2n\\times 2n}$\u4e2d: $$ c_{k} =\\begin{cases} t_k , 0 \\le k \\le n - 1\\ t_0 , k=n\\ t_{k -2n}, n+1\\le k \\le 2n-1 \\end{cases} , $$ \u5373\uff0c $$ \\mathbf C=\\left[\\begin{array}{ccccc|ccccc} t_0 & t_{-1} & \\ldots & \\ldots & t_{-n+1} & t_0 & t_{n-1} & \\ldots & t_2 & t_1 \\ t_1 & t_0 & \\ddots & & \\vdots & t_{-n+1} & \\ddots & \\ddots & & t_2 \\ t_2 & \\ddots & \\ddots & \\ddots & \\vdots & \\vdots & \\ddots & & \\ddots & \\vdots \\ \\vdots & & \\ddots & t_0 & t_{-1} & t_{-2} & & \\ddots & \\ddots & t_{n-1} \\ t_{n-1} & \\ldots & \\ldots & t_1 & t_0 & t_{-1} & t_{-2} & \\ldots & t_{-n+1} & t_0 \\ \\hline t_0 & t_{n-1} & \\ldots & \\ldots & t_1 & t_0 & t_{-1} & \\ldots & \\ldots & t_{-n+1} \\ t_{-n+1} & \\ddots & \\ddots & & t_2 & t_1 & t_0 & \\ddots & & \\vdots \\ \\vdots & \\ddots & & \\ddots & \\vdots & t_2 & \\ddots & \\ddots & \\ddots & \\vdots \\ t_{-2} & & \\ddots & \\ddots & t_{n-1} & \\vdots & & \\ddots & t_0 & t_{-1} \\ t_{-1} & t_{-2} & \\ldots & \\ldots & t_0 & t_{n-1} & \\ldots & \\ldots & t_1 & t_0 \\end{array}\\right] \\in \\mathbb R^{2n\\times 2n}. $$ \u4f7f\u7528\u5206\u5757\u77e9\u9635\u7684\u7b26\u53f7\uff0c\u6211\u4eec\u53ef\u4ee5\u5b9a\u4e49\uff1a $$ \\begin{gathered} \\mathbf C = \\left[\\begin{matrix} \\mathbf C_1 & \\mathbf C_2\\ \\mathbf C_3 & \\mathbf C_4\\ \\end{matrix}\\right] \\in \\mathbb R^{2n\\times 2n},\\mathbf C_s \\in \\mathbb R^{n \\times n}, s=1,2,3,4, \\mathbf C_1 = \\mathbf T \\end{gathered}. $$ \u6709\u4e86\u4e0a\u8ff0\u51c6\u5907\u5de5\u4f5c\uff0c\u53ef\u4ee5\u5f97\u5230Toeplitz matrix-vector production\u7684\u5feb\u901f\u7b97\u6cd5\u3002 \u5feb\u901f\u77e9\u9635\u4e58\u6cd5 \u5bf9\u4e8e\u5411\u91cf$\\mathbf x\\in \\mathbb R^{n}$, \u5b9a\u4e49: $$ \\mathbf x_1 = \\left[\\begin{matrix} \\mathbf x\\ \\mathbf 0_n \\end{matrix}\\right] \\in \\mathbb R^{2n}, $$ \u6240\u4ee5\uff0c $$ \\mathbf C \\mathbf x_1 =\\left[\\begin{matrix} \\mathbf C_1 & \\mathbf C_2\\ \\mathbf C_3 & \\mathbf C_4\\ \\end{matrix}\\right]\\left[\\begin{matrix} \\mathbf x\\ \\mathbf 0_n \\end{matrix}\\right]=\\left[\\begin{matrix} \\mathbf C_1 \\mathbf x\\ \\mathbf C_3 \\mathbf x \\end{matrix}\\right]=\\left[\\begin{matrix} \\mathbf T \\mathbf x\\ \\mathbf C_3 \\mathbf x \\end{matrix}\\right] \\in \\mathbb R^{2n}, $$ \u56e0\u6b64: $$ \\left[\\begin{matrix} {\\mathbf I} n & {\\mathbf 0} {n\\times n} \\end{matrix}\\right]\\mathbf C \\mathbf x_1 = \\left[\\begin{matrix} \\mathbf I_n & \\mathbf 0_{n\\times n} \\end{matrix}\\right]\\left[\\begin{array}{c} \\mathbf T \\mathbf x\\ \\mathbf C_3 \\mathbf x \\end{array}\\right]=\\mathbf T \\mathbf x. $$ \u5173\u4e8e\u65f6\u95f4\u590d\u6742\u5ea6\uff0c\u6ce8\u610f\u5230\u6211\u4eec\u662f\u5c06$n\\times n$\u7684Toeplitz matrix\u5d4c\u5165\u5230\u4e00\u4e2a$2n\\times 2n$\u7684Circulant matrix\u4e2d\uff0c\u6240\u4ee5\u65f6\u95f4\u590d\u6742\u5ea6\u4ecd\u7136\u4e3a$O(n\\log n)$\u3002 \u5b9e\u73b0 \u548cCirculant matrix\u7684\u60c5\u5f62\u7c7b\u4f3c\uff0c\u53ef\u4ee5\u5229\u7528 fft \u5b9e\u73b0\u4e0a\u8ff0\u8ba1\u7b97\uff1a def tno_fft(x, t): # x: (b, n, d) # t: (2 * n, d), t0, t1, ..., t(n-1), t0, t_(-(n-1)), ... , t_(-1) n = x.shape[1] t = t.unsqueeze(0) x_fft = torch.fft.rfft(x, 2 * n, dim=-2) t_fft = torch.fft.rfft(t, 2 * n, dim=-2) o_fft = x_fft * t_fft o = torch.fft.irfft(o_fft, 2 * n, dim=-2)[:, :n] return o \u9a8c\u8bc1\u5b9e\u73b0 \u5728\u4e4b\u524d\u7684\u8ba8\u8bba\u4e2d\uff0c\u6211\u4eec\u7ed9\u51fa\u4e86Tno\u7684\u4e09\u79cd\u5b9e\u73b0\u65b9\u5f0f\uff0c\u5728\u672c\u8282\u4e2d\uff0c\u6211\u4eec\u5c06\u9a8c\u8bc1\u8fd9\u4e9b\u5b9e\u73b0\u7684\u6b63\u786e\u6027\u3002 b = 2 n = 16 d = 128 t_zero = torch.randn(1, d) # t1, ..., t(n-1) t_pos = torch.randn(n - 1, d) # t-(n-1), ... , t-1 t_neg = torch.randn(n - 1, d) t1 = torch.cat([t_neg, t_zero, t_pos], dim=0).cuda() t2 = torch.cat([t_zero, t_pos, t_zero, t_neg], dim=0).cuda() x = torch.randn(b, n, d).cuda() o1 = tno_naive(x, t1) o2 = tno_matrix(x, t1) o3 = tno_fft(x, t2) print(f\"The output error between tno_naive and tno_matrix is {torch.norm(o1 - o2)}\") print(f\"The output error between tno_naive and tno_matrix is {torch.norm(o1 - o3)}\") The output error between tno_naive and tno_matrix is 2.414959999441635e-05 The output error between tno_naive and tno_matrix is 5.38119456905406e-05 \u8865\u5145 \u73b0\u5728\u6211\u4eec\u5df2\u7ecf\u5b8c\u6210\u4e86\u5927\u90e8\u5206\u5185\u5bb9\uff0c\u8fd9\u91cc\u6700\u540e\u8865\u5145\u5982\u4f55\u5c06Tno\u9002\u914d\u5230Autoregressive Language Model(causal)\u7684\u60c5\u5f62\u3002\u548cAttention\u7c7b\u4f3c\uff0c\u53ea\u8981\u4fdd\u8bc1Toeplitz matrix\u7684\u4e0a\u4e09\u89d2\u90e8\u5206\u4e3a$0$\u5373\u53ef\uff0c\u5373\uff1a $$ \\mathbf T=\\left[\\begin{matrix} t_0 & 0 & 0 & \\cdots & \\cdots & 0 \\ t_1 & t_0 & 0 & \\ddots & & \\vdots \\ t_2 & t_1 & \\ddots & \\ddots & \\ddots & \\vdots \\ \\vdots & \\ddots & \\ddots & \\ddots & 0 & 0 \\ \\vdots & & \\ddots & t_1 & t_0 &0 \\ t_{n-1} & \\ldots & \\ldots & t_2 & t_1 & t_0 \\end{matrix}\\right] \\in \\mathbb R^{n\\times n}. $$ \u5728\u5b9e\u73b0\u65f6\uff0c\u6ce8\u610f\u5230 fft \u662fzero padding\uff0c\u6240\u4ee5\u53ea\u9700\u8981\u5c06\u8f93\u5165\uff1a t2 = torch.cat([t_zero, t_pos, t_zero, t_neg], dim=0).cuda() \u4fee\u6539\u4e3a\u4e0b\u5f0f\u5373\u53ef\uff1a t2 = torch.cat([t_zero, t_pos, t_zero], dim=0).cuda() \u5c0f\u7ed3 \u5728\u672c\u8282\u4e2d\uff0c\u6211\u4eec\u4ecenaive\u7684\u7b97\u6cd5\u5f00\u59cb\uff0c\u6700\u7ec8\u5f97\u5230\u4e86\u4e00\u4e2a\u57fa\u4e8eFFT\u7b97\u6cd5\u7684\u9ad8\u6548\u5b9e\u73b0\uff0c\u5e76\u4e14\u7ed9\u51fa\u5904\u7406\u5355\u5411\u60c5\u5f62\u7684\u65b9\u6848\u3002 Rpe\u7684\u5b9e\u73b0 \u6ce8\u610f\u5230Tno\u7684\u8ba1\u7b97\u6d89\u53ca\u5230$x,t$\uff0c$x$\u662f\u8f93\u5165\uff0c$t$\u662f\u76f8\u5bf9\u4f4d\u7f6e\u7cfb\u6570\uff0c\u6240\u4ee5\u4e0b\u4e00\u6b65\u5c31\u662f\u5982\u4f55\u8ba1\u7b97$t$\u3002\u5bf9\u4e8e\u5e8f\u5217\u957f\u5ea6\u4e3a$n$\uff0c\u7279\u5f81\u7ef4\u5ea6\u4e3a$d$\u7684\u6a21\u578b\uff0c\u6211\u4eec\u4e00\u5171\u6709$(2n-1)\\times d$\u4e2a\u7cfb\u6570\uff0c\u6240\u4ee5\u63a5\u4e0b\u6765\u7684\u95ee\u9898\u5c31\u662f\u5982\u4f55\u5f97\u5230\u8fd9\u4e9b\u7cfb\u6570\u3002 Naive\u5b9e\u73b0 \u6700\u7b80\u5355\u7684\u601d\u8def\u5c31\u662f\u76f4\u63a5\u7ed9\u6a21\u578b\u589e\u52a0$(2n-1)\\times d$\u4e2a\u53c2\u6570\uff0c\u4f46\u662f\u8fd9\u6837\u505a\u6709\u51e0\u4e2a\u95ee\u9898\uff1a 1. \u5f53\u5e8f\u5217\u957f\u5ea6$n$\u6bd4\u8f83\u5927\u7684\u65f6\u5019\uff0c\u6a21\u578b\u53c2\u6570\u91cf\u4f1a\u975e\u5e38\u591a\uff1b 2. \u5c3d\u7ba1\u6211\u4eec\u6709$(2n-1)\\times d$\u4e2a\u7cfb\u6570\uff0c\u4f46\u662f\u5bf9\u4e8e\u6bcf\u4e2achannel\u7684$2n-1$\u4e2a\u7cfb\u6570\uff0c\u4e0d\u80fd\u5b8c\u5168\u5047\u8bbe\u4ed6\u4eec\u662f\u72ec\u7acb\u7684\uff0c\u4f8b\u5982$t_1$\u548c$t_{-1}$\u5fc5\u7136\u6709\u5185\u5728\u8054\u7cfb\uff1b 3. \u65e0\u6cd5\u5904\u7406\u4efb\u610f\u957f\u7684\u5e8f\u5217\uff1b 1. \u8fd9\u70b9\u53ef\u4ee5\u7406\u89e3\u4e3a\uff0c\u5f53\u8d85\u8fc7\u6700\u5927\u5e8f\u5217\u957f\u5ea6\u65f6\uff0c\u6ca1\u6709\u5bf9\u5e94\u7684\u7cfb\u6570\uff0c\u6240\u4ee5\u6a21\u578b\u4e5f\u6ca1\u6709 \u5916\u63a8\u6027 \uff1b \u90a3\u4e48\u662f\u5426\u6709\u529e\u6cd5\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u5462\uff1f\u56de\u7b54\u662f\u80af\u5b9a\u7684\u3002 Relative Position Encoder \u5bf9\u4e8e\u95ee\u9898\uff11\uff0c\uff12\uff0c\u6211\u4eec\u5229\u7528\u67d0\u79cd\u65b9\u5f0f\u53c2\u6570\u5316\u8fd9$(2n-1)\\times d$\u4e2a\u53c2\u6570\u5373\u53ef\uff0c\u6700\u7b80\u5355\u65b9\u5f0f\u5c31\u662f\u4f7f\u7528\u795e\u7ecf\u7f51\u7edc\uff0c\u7279\u522b\u7684\uff0c\u6211\u4eec\u4f7f\u7528\u7684\u662f\u4e00\u4e2a\u540d\u4e3aRelative Position Encoder(RPE)\u7684\u7f51\u7edc\uff0c\u7f51\u7edc\u7684\u8f93\u5165\u662f1\u7ef4\u5b9e\u6570$-(n-1), \\ldots, (n-1)$\uff0c\u8f93\u51fa\u662f$d$\u7ef4\u7279\u5f81\u3002\u5728\u4f7f\u7528\u65f6\uff0c\u6211\u4eec\u4f1a\u8f93\u5165$[-(n-1),\\ldots, (n-1)]^{\\top} \\in \\mathbb R^{2n-1}$\uff0c\u8f93\u51fa\u7684\u5f62\u72b6\u662f$(2n-1)\\times d$\u3002 \u5bf9\u4e8e\u95ee\u9898\uff13\uff0c\u6211\u4eec\u73b0\u5728\u53ef\u4ee5\u4e00\u5b9a\u7a0b\u5ea6\u4e0a\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u73b0\u5728\u53ea\u8981\u5c06\u76f8\u5bf9\u4f4d\u7f6e\uff08\u8d85\u51fa\u8bad\u7ec3\u65f6\u7684\u6700\u5927\u8bad\u7ec3\u957f\u5ea6\u4e5f\u53ef\uff09\u8f93\u5165\u5230RPE\u4e2d\uff0c\u5373\u53ef\u5f97\u5230\u5bf9\u5e94\u7cfb\u6570\u3002\u4f46\u662f\u8fd9\u6837\u8fd8\u8fdc\u8fdc\u4e0d\u591f\uff0c\u56e0\u4e3a\u8fd9\u79cd\u65b9\u5f0f\u53ea\u662f\u8ba9\u6a21\u578b\u201c\u5f3a\u884c\u201d\u8ba1\u7b97\u4e86\u4e00\u4e2a\u503c\uff0c\u4e3a\u4e86\u4f7f\u5f97\u6027\u80fd\u6b63\u5e38\uff0c\u6211\u4eec\u53c2\u8003\u4e86 Alibi \u7684\u65b9\u6848\uff0c\u4f7f\u7528\u4e86\u6307\u6570\u8870\u51cf\u7684\u5f62\u5f0f\uff0c\u5373\uff1a $$ \\bar t_{i-j}=\\lambda^{|i-j|} t_{i-j}, 0< \\lambda < 1. $$ \u5176\u4e2d$\\lambda$\u662f\u4e00\u4e2a\u8d85\u53c2\uff0c\u6211\u4eec\u5728$n=512$\u65f6\u9009\u62e9$\\lambda=0.99$\u3002 \u5b9e\u73b0Relative Position Encoder \u6709\u4e86\u4e4b\u524d\u7684\u8ba8\u8bba\uff0c\u6211\u4eec\u7ed9\u51faRelative Position Encoder\u7684\u5b9e\u73b0\uff0c\u672c\u8d28\u662f\u5c31\u662f\u4e00\u4e2a\u5168\u8fde\u63a5\u7f51\u7edc\uff0c\u52a0\u4e0a\u5f52\u4e00\u5316\u548c\u6fc0\u6d3b\u51fd\u6570\uff1a class Rpe(nn.Module): def __init__( self, dim, outdim, residual, act=\"relu\", bias=True, layers=3, ): super().__init__() self.residual = residual self.outdim = outdim self.pos_dim = dim self.act = act self.pos_proj = nn.Linear(1, self.pos_dim, bias=bias) self.layers = nn.ModuleList([]) for i in range(layers): self.layers.append( nn.Sequential( nn.LayerNorm(self.pos_dim), self.get_act(), nn.Linear(self.pos_dim, self.pos_dim, bias=bias), ) ) self.out = nn.Sequential( nn.LayerNorm(self.pos_dim), self.get_act(), nn.Linear(self.pos_dim, self.outdim, bias=bias), ) def get_act(self): if self.act == \"silu\": return nn.SiLU(inplace=True) else: return nn.ReLU(inplace=True) def forward(self, biases): x = self.pos_proj(biases) if self.residual: for m in self.layers: x = m(x) + x else: for m in self.layers: x = m(x) x = self.out(x) return x \u5c06Tno\u548cRpe\u5408\u5e76 \u5728\u6211\u4eec\u7684\u539f\u59cb\u5b9e\u73b0\u4e2d\uff0cRpe\u662f\u548cTno\u5408\u5e76\u5728\u4e00\u8d77\u7684\uff0c\u5b8c\u6574\u7684\u5b9e\u73b0\u5982\u4e0b\uff1a class Tno(nn.Module): def __init__( self, h, dim, rpe_dim, causal=False, use_decay=False, residual=False, act=\"relu\", par_type=1, gamma=0.99, bias=True, layers=3, ): super().__init__() self.h = h self.dim = dim self.causal = causal self.par_type = par_type self.zero_value = 0 self.use_decay = use_decay if self.use_decay: self.gamma = nn.Parameter(torch.ones(h, 1, dim) * gamma, requires_grad=False) self.rpe = Rpe( dim=rpe_dim, outdim=h * dim, residual=residual, act=act, bias=bias, layers=layers, ) if self.causal: self.forward = self.forward_causal else: self.forward = self.forward_non_causal def get_pos(self, n): if self.par_type == 1: index = torch.arange(1, 1 + n).reshape(n, -1) * 1.0 elif self.par_type == 2: index = torch.arange(1, 1 + n).reshape(n, -1) * 1.0 / n elif self.par_type == 3: index = torch.exp(torch.arange(1, 1 + n).reshape(n, -1) * 1.0 / n) return index def get_zero(self): index = torch.zeros(1).reshape(1, -1) * 1.0 if self.par_type == 3: index = torch.exp(index) return index def get_neg(self, n): if self.causal: index = torch.ones(self.h * n * self.dim).reshape(self.h, n, self.dim) * self.zero_value else: if self.par_type == 1: index = -torch.arange(1, 1 + n).flip(0).reshape(n, -1) * 1.0 elif self.par_type == 2: index = -torch.arange(1, 1 + n).flip(0).reshape(n, -1) * 1.0 / n return index def rpe_transform(self, x): # n, 1 -> n, (d * h) res = self.rpe(x) # n, (d * h) -> h, n, d res = rearrange(res, 'n (h d) -> h n d', h=self.h) return res def forward_causal(self, x, dim=-2): # x: b, h, n, d n = x.shape[dim] # a0, a1, ... , a(n-1), a0, a(-(n-1)), ... , a(-1) ##### coef # 1, d, 1 -> h, 1, d zero = self.rpe_transform(self.get_zero().to(x)) pos = self.rpe_transform(self.get_pos(n - 1).to(x)) if self.use_decay: coef = torch.arange(1, n).reshape(1, -1, 1).to(x) gamma = self.gamma gamma = gamma ** coef pos = gamma * pos a = torch.cat([zero, pos, zero], dim=1) a = self.act_fun(a) # x: b, h, n, d # a: h, l, d output = self.compute(x, a, dim, n) return output def forward_non_causal(self, x, dim=-2): # x: b, h, n, d n = x.shape[dim] # a0, a1, ... , a(n-1), a0, a(-(n-1)), ... , a(-1) ##### coef # 1, d, 1 -> h, 1, d zero = self.rpe_transform(self.get_zero().to(x)) pos = self.rpe_transform(self.get_pos(n - 1).to(x)) neg_index = self.get_neg(n - 1).to(x) if self.causal: neg = neg_index else: neg = self.rpe_transform(neg_index) if self.use_decay: coef = torch.arange(1, n).reshape(1, -1, 1).to(x) gamma = self.gamma gamma = gamma ** coef pos = gamma * pos neg = torch.flip(gamma, dims=[1]) * neg a = torch.cat([zero, pos, zero, neg], dim=1) a = self.act_fun(a) # x: b, h, n, d # a: h, l, d output = self.compute(x, a, dim, n) return output def compute(self, x, a, dim, n): # x: b, h, n, d # a: h, n, d y = torch.fft.rfft(x, 2 * n, dim=dim) v = torch.fft.rfft(a, 2 * n, dim=dim).unsqueeze(0) u = v * y output = torch.fft.irfft(u, 2 * n, dim=dim)[:, :, :n, :] return output Tnn layer\u7684\u5b9e\u73b0 \u6709\u4e86\u4e4b\u524d\u7684\u94fa\u57ab\uff0c\u6211\u4eec\u53ef\u4ee5\u4ecb\u7ecdTnn Layer\uff0c\u8be5\u6a21\u5757\u5305\u542b\u4e00\u4e2aToken mixer(GTU)\u4ee5\u53ca\u4e00\u4e2aChannel mixer(GLU)\uff0c\u7531\u4e8eGLU\u548cGTU\u975e\u5e38\u76f8\u4f3c\uff0c\u6240\u4ee5\u6211\u4eec\u4eceGLU\u5f00\u59cb\u4ecb\u7ecd\u3002 GLU GLU \u662f\u5229\u7528Gate\u7684\u5f62\u5f0f\u8fbe\u5230Channel mixing\u7684\u4f5c\u7528\uff0c\u5199\u6210\u6570\u5b66\u516c\u5f0f\u4e3a\uff1a $$ \\mathbf O = [f({\\mathbf X} {\\mathbf W_1}) \\odot ({\\mathbf X} {\\mathbf W_2})] {\\mathbf W_3}. $$ \u5b9e\u73b0\u5982\u4e0b\uff1a class GLU(nn.Module): def __init__(self, d1, d2, act_fun, fina_act=\"None\", dropout=0.0, bias=True): super().__init__() self.l1 = nn.Linear(d1, d2, bias=bias) self.l2 = nn.Linear(d1, d2, bias=bias) self.l3 = nn.Linear(d2, d1, bias=bias) self.act_fun = get_activation_fn(act_fun) self.p = dropout if self.p > 0.0: self.dropout = nn.Dropout(p=dropout) self.fina_act = get_activation_fn(fina_act) def forward(self, x): o1 = self.l1(x) weight = self.act_fun(o1) if self.p > 0.0: weight = self.dropout(weight) o2 = self.l2(x) output = weight * o2 output = self.l3(output) output = self.fina_act(output) return output GTU GTU\u53c2\u8003\u4e86GLU\u7684\u601d\u8def\uff0c\u552f\u4e00\u7684\u4e0d\u540c\u662f\u5728\u5176\u4e2d\u4e00\u4e2a\u5206\u652f\u4e0a\u4f7f\u7528\u4e86 Tno \uff0c\u5e76\u4e14\u589e\u52a0\u4e00\u4e2a\u6fc0\u6d3b\u51fd\u6570\uff0c\u5199\u6210\u6570\u5b66\u516c\u5f0f\u5373\u4e3a\uff1a $$ \\mathbf O = [f({\\mathbf X} {\\mathbf W_1}) \\odot (\\mathbf T f({\\mathbf X} {\\mathbf W_2}))] {\\mathbf W_3}. $$ \u5b9e\u73b0\u5982\u4e0b\uff1a class Gtu(nn.Module): def __init__( self, embed_dim, num_heads, bias=True, act_fun=\"silu\", causal=False, expand_ratio=3, use_norm=False, norm_type=\"layernorm\", use_decay=False, rpe_layers=3, rpe_embedding=512, rpe_act=\"relu\", normalize=False, par_type=1, residual=False, gamma=0.99, ): super().__init__() self.embed_dim = embed_dim self.expand_ratio = expand_ratio self.num_heads = num_heads self.normalize = normalize d1 = int(self.expand_ratio * embed_dim) d1 = (d1 // self.num_heads) * self.num_heads self.head_dim = d1 // num_heads # linear projection self.v_proj = nn.Linear(embed_dim, d1, bias=bias) self.u_proj = nn.Linear(embed_dim, d1, bias=bias) self.o = nn.Linear(d1, embed_dim, bias=bias) self.act = get_activation_fn(act_fun) # tno self.toep = Tno( h=num_heads, dim=self.head_dim, rpe_dim=rpe_embedding, causal=causal, use_decay=use_decay, residual=residual, act=rpe_act, par_type=par_type, gamma=gamma, bias=bias, layers=rpe_layers, ) # norm self.norm_type = norm_type self.use_norm = use_norm def forward(self, x): # x: b, n, d num_heads = self.num_heads u = self.act(self.u_proj(x)) v = self.act(self.v_proj(x)) # reshape v = rearrange(v, 'b n (h d) -> b h n d', h=num_heads) output = self.toep(v, dim=-2, normalize=self.normalize) output = rearrange(output, 'b h n d -> b n (h d)') output = u * output output = self.o(output) return output TnnLayer \u6709\u4e86\u4e4b\u524d\u7684\u51c6\u5907\u5de5\u4f5c\uff0c\u6211\u4eec\u5f88\u5bb9\u6613\u5b9e\u73b0\u51faTnnLayer\uff0c\u56e0\u4e3a\u8fd9\u53ea\u4e0d\u8fc7\u662fGTU\u548cGLU\u7684\u5806\u53e0\uff1a class TnnLayer(nn.Module): def __init__( self, dim, num_heads, rpe_embedding, glu_dim, # model params prenorm=True, norm_type=\"layernorm\", # gtu params causal=False, gtu_act=\"silu\", expand_ratio=3, use_decay=False, gamma=0.999, # rpe params rpe_act=\"relu\", rpe_layers=3, # glu params glu_act=\"silu\", ): super().__init__() self.token_mixer = Gtu( # gtu params embed_dim=dim, num_heads=num_heads, act_fun=gtu_act, norm_type=norm_type, causal=causal, expand_ratio=expand_ratio, use_decay=use_decay, gamma=gamma, # rpe params rpe_embedding=rpe_embedding, rpe_act=rpe_act, rpe_layers=rpe_layers, ) self.token_norm = nn.LayerNorm(dim) self.feature_norm = nn.LayerNorm(dim) self.feature_mixer = GLU( d1=dim, d2=glu_dim, act_fun=glu_act, ) def forward(self, x): x = x + self.token_mixer(self.token_norm(x)) x = x + self.feature_mixer(self.feature_norm(x)) return x \u5728\u4f7f\u7528\u65f6\uff0c\u60a8\u53ea\u9700\u8981\u5c06TransformerLayer\u66ff\u6362\u6210TnnLayer\u5373\u53ef\u3002 \u5c0f\u7ed3 \u5728\u672c\u8282\u4e2d\uff0c\u6211\u4eec\u5b8c\u6210\u4e86TnnLayer\u7684\u5b9e\u73b0\uff0c\u6709\u4e86\u4e4b\u524d\u7684\u94fa\u57ab\u5de5\u4f5c\uff0c\u8fd9\u4e00\u5207\u5e76\u4e0d\u56f0\u96be\u3002\u73b0\u5728\uff0c\u60a8\u5df2\u7ecf\u53ef\u4ee5\u5c06Tnn\u5e94\u7528\u5230\u60a8\u7684\u9879\u76ee\u4e2d\u4e86\u3002 \u5168\u6587\u603b\u7ed3 \u901a\u8fc7\u4e4b\u524d\u7684\u5185\u5bb9\uff0c\u60a8\u5e94\u8be5\u5bf9TNN\u6709\u6240\u4e86\u89e3\uff0c\u8fd9\u91cc\uff0c\u8ba9\u6211\u4eec\u5bf9\u5168\u6587\u7684\u6838\u5fc3\u8fdb\u884c\u603b\u7ed3\uff1a Transformer\u53ef\u4ee5\u5206\u4e3aToken mixing\u548cChannel mixing\uff1b Attention\u7684\u4f5c\u7528\u662fToken mixing\uff0c\u800c\u76f8\u5bf9\u4f4d\u7f6e\u4fe1\u606f\u5bf9Attention\u5f88\u91cd\u8981\uff0c\u6211\u4eec\u63d0\u51fa\u4f7f\u7528\u76f8\u5bf9\u4f4d\u7f6e\u4fe1\u606f(Toepltiz matrix)\u6765\u4ee3\u66ffAttention Matrix\uff1b \u4f7f\u7528Toeplitz matrix\u8fdb\u884c\u77e9\u9635\u4e58\u6cd5\u53ef\u4ee5\u52a0\u901f\uff0c\u6240\u4ee5\u6211\u4eec\u7684\u65b9\u6cd5\u7406\u8bba\u4e0a\u901f\u5ea6\u5f88\u5feb\uff1b Toeplitz matrix\u7684\u7cfb\u6570\u53ef\u4ee5\u4f7f\u7528Rpe\u8fdb\u884c\u53c2\u6570\u5316\uff0c\u4ece\u800c\u51cf\u5c11\u53c2\u6570\uff0c\u7ed3\u5408\u6307\u6570\u8870\u51cf\u53ef\u4ee5\u5f97\u5230\u5916\u63a8\u6027\uff1b \u5f53\u7136\uff0cTNN\u8fd8\u6709\u5f88\u591a\u95ee\u9898\u5b58\u5728\uff0c\u4f8b\u5982\uff1a \u4e3a\u4ec0\u4e48\u76f8\u5bf9\u4f4d\u7f6e\u4fe1\u606f\u5c31\u8db3\u591f\u8fdb\u884c\u5e8f\u5217\u5efa\u6a21\uff1f TNN\u771f\u7684\u53ea\u4f7f\u7528\u4e86\u76f8\u5bf9\u4f4d\u7f6e\u4fe1\u606f\u5417\uff1f TNN\u80fd\u8fbe\u5230\u7406\u8bba\u901f\u5ea6\u4e0a\u754c\u5417\uff1f TNN\u4e0d\u80fd\u505a\u54ea\u4e9b\u4efb\u52a1\uff1f TNN\u6709\u54ea\u4e9b\u5148\u9a8c\u5047\u8bbe\uff1f \u5173\u4e8e\u8fd9\u4e9b\u95ee\u9898\uff0c\u6211\u4eec\u5c06\u5728\u540e\u7eed\u7684\u535a\u5ba2\u4e2d\u56de\u7b54\uff0c\u671f\u5f85\u60a8\u7684\u518d\u6b21\u9605\u8bfb\u3002","title":"Zh"},{"location":"zh/#_1","text":"\u76ee\u5f55 \u9884\u5907\u77e5\u8bc6 Token mixing and channel mixing \u76f8\u5bf9\u4f4d\u7f6e\u7f16\u7801 TNN\u7684\u52a8\u673a TNN\u7684\u5b9e\u73b0 \u51c6\u5907\u5de5\u4f5c Tno\u7684\u5b9e\u73b0 Naive\u5b9e\u73b0 Matrix production\u5b9e\u73b0 FFT\u5b9e\u73b0 Circulant matrix \u5b9a\u4e49 \u5feb\u901f\u77e9\u9635\u4e58\u6cd5 \u5b9e\u73b0 \u5c0f\u7ed3 Toeplitz matrix \u5b9a\u4e49 \u5feb\u901f\u77e9\u9635\u4e58\u6cd5 \u5b9e\u73b0 \u9a8c\u8bc1\u5b9e\u73b0 \u8865\u5145 \u5c0f\u7ed3 Rpe\u7684\u5b9e\u73b0 Naive\u5b9e\u73b0 Relative Position Encoder \u5b9e\u73b0Relative Position Encoder \u5c06Tno\u548cRpe\u5408\u5e76 Tnn layer\u7684\u5b9e\u73b0 GLU GTU TnnLayer \u5c0f\u7ed3 \u5168\u6587\u603b\u7ed3","title":"\u76ee\u5f55"},{"location":"zh/#_2","text":"","title":"\u9884\u5907\u77e5\u8bc6"},{"location":"zh/#token-mixing-and-channel-mixing","text":"\u8ba9\u6211\u4eec\u9996\u5148\u4eceTransformer\u5f00\u59cb\u3002Transformer\u4f5c\u4e3a\u4e00\u4e2a\u7f51\u7edc\u7ed3\u6784\u5df2\u7ecf\u5e2d\u5377\u4e86\u5404\u4e2a\u9886\u57df\uff0c\u5176\u6838\u5fc3\u90e8\u5206\u4e3b\u8981\u53ef\u4ee5\u7531\u5982\u4e0b\u4e24\u4e2a\u8ba1\u7b97\u516c\u5f0f\u63cf\u8ff0\uff1a $$ \\begin{aligned} \\mathbf X_1 &=\\mathrm{Norm}(\\mathbf X + \\mathrm{MHA}(\\mathbf X)),\\ \\mathbf O &= \\mathrm{Norm}(\\mathbf X_1 + \\mathrm{FFN}(\\mathbf X_1)). \\end{aligned} $$ \u5176\u4e2d$\\mathbf X \\in \\mathbb R^{n\\times d}$\u662f\u8f93\u5165\uff08\u4e5f\u53ef\u4ee5\u79f0\u4e3atoken matrix\uff0c\u5176\u4e2d\u77e9\u9635\u7684\u6bcf\u4e00\u884c\u4e3a\u4e00\u4e2atoken\u7684\u5411\u91cf\u8868\u793a\uff09\uff0c$n$\u662f\u5e8f\u5217\u957f\u5ea6\uff0c$d$\u662f\u7279\u5f81\u7ef4\u5ea6\u3002 \u65e2\u7136\u73b0\u5728\u6709\u4e24\u4e2a\u4e3b\u8981\u6a21\u5757\u2014\u2014$\\mathrm {MHA}$\u548c$\\mathrm {FFN}$\uff0c\u90a3\u4e48\u4ed6\u4eec\u7684\u4f5c\u7528\u662f\u5426\u6709\u6240\u4e0d\u540c\u5462\uff1f\u5728 Metaformer \u4e00\u6587\u4e2d\uff0c\u7814\u7a76\u8005\u6307\u51fa\uff0c$\\mathrm {MHA}$\u7684\u4e3b\u8981\u4f5c\u7528\u662fToken mixing\uff0c\u800c$\\mathrm {FFN}$\u7684\u4e3b\u8981\u4f5c\u7528\u662fChannel mixing\u3002 \u8fd9\u662f\u4ec0\u4e48\u610f\u601d\u5462\uff1f\u6211\u4eec\u53ef\u4ee5\u4ece\u77e9\u9635\u4e58\u6cd5\u7684\u89d2\u5ea6\u6e05\u6670\u7684\u7406\u89e3\u8fd9\u70b9\uff1a\u7ed9\u5b9a\u8f93\u5165\uff08token matrix\uff09$\\mathbf X \\in \\mathbb R^{n\\times d}$\uff0c\u8003\u8651\u77e9\u9635\u4e58\u6cd5$\\mathbf A \\mathbf X$\u548c$\\mathbf X \\mathbf B$\uff0c\u90a3\u4e48\uff1a - $\\mathbf A \\mathbf X$\u8868\u793a\u77e9\u9635$\\mathbf X$\u884c\u7684\u7ebf\u6027\u7ec4\u5408\uff0c\u800c\u6bcf\u4e00\u884c\u8868\u793a\u4e00\u4e2atoken\uff0c\u5373token\u7684\u7ebf\u6027\u7ec4\u5408\uff0c\u6240\u4ee5\u79f0\u4e3atoken mixing\uff1b - $\\mathbf X \\mathbf B$\u8868\u793a\u77e9\u9635$\\mathbf X$\u5217\u7684\u7ebf\u6027\u7ec4\u5408\uff0c\u800c\u6bcf\u4e00\u5217\u8868\u793a\u4e00\u4e2achannel\uff0c\u5373channel\u7684\u7ebf\u6027\u7ec4\u5408\uff0c\u6240\u4ee5\u79f0\u4e3achannel mixing\uff1b \u5728Transformer\u4e2d\uff0c\u77e9\u9635$\\mathbf A$\u5373\u4e3a$\\mathrm{Softmax}(\\mathbf Q \\mathbf K^{\\top} /\\sqrt{d})$\uff0c\u77e9\u9635$\\mathbf B$\u5373\u4e3a$\\mathrm {FFN}$\u4e2d\u7684\u5168\u8fde\u63a5\u5c42\u3002 \u5927\u591a\u6570\u5bf9Transformer\u7684\u6539\u8fdb\u90fd\u662f\u96c6\u4e2d\u5728token mixing:$\\mathbf A \\mathbf X$\u7684\u8ba1\u7b97\u4e0a\uff0c\u4ee5\u5404\u79cd\u5404\u6837\u7684\u65b9\u5f0f\u964d\u4f4e\u5176\u8fd0\u7b97\u590d\u6742\u5ea6\uff0cTNN\u4e5f\u662f\u4f7f\u7528\u4e86\u7c7b\u4f3c\u7684\u601d\u8def\uff0c\u6700\u6838\u5fc3\u7684\u4e00\u70b9\u5c31\u662f\u5229\u7528\u4e86\u76f8\u5bf9\u4f4d\u7f6e\u7f16\u7801\uff0c\u6216\u8005\u8bf4\uff0cToeplitz\u77e9\u9635\u3002","title":"Token mixing and channel mixing"},{"location":"zh/#_3","text":"\u4f4d\u7f6e\u7f16\u7801\u662fTransformer\u4e2d\u7684\u91cd\u8981\u7ec4\u6210\u90e8\u5206\uff0c\u4e00\u5f00\u59cb\u5e7f\u4e3a\u4f7f\u7528\u7684\u662f \u7edd\u5bf9\u4f4d\u7f6e\u7f16\u7801(APE) \uff0c\u8fd9\u79cd\u7f16\u7801\u7684\u65b9\u5f0f\u53ef\u4ee5\u7528\u5982\u4e0b\u8ba1\u7b97\u65b9\u5f0f\u6982\u62ec\uff1a $$ \\mathbf x_i =\\mathbf w_i + \\mathbf p_i. $$ \u5176\u4e2d$\\mathbf w_i$\u8868\u793a\u7b2c$i$\u4e2a\u8bcd\u7684word embedding\uff0c$\\mathbf p_i$\u8868\u793a\u7b2c$i$\u4e2a\u4f4d\u7f6e\u7684position embedding\u3002 \u540e\u6765\uff0c\u6709\u7814\u7a76\u4eba\u5458\u53d1\u73b0\uff0c\u5728\u5e8f\u5217\u5efa\u6a21\u4e2d\uff0c\u8bcd\u7684\u76f8\u5bf9\u4f4d\u7f6e\u4fe1\u606f\uff0c\u53ef\u80fd\u6bd4\u8bcd\u7684\u7edd\u4f4d\u7f6e\u4fe1\u606f\u66f4\u52a0\u91cd\u8981\u3002 \u4f8b\u5982\"\u6211\u5e74\u7eaa\u6bd4\u4f60\u5927\"\u7684\u8bed\u610f\u548c\"\u6211\u5e74\u7eaa\u6bd4\u4f60\u5927\"\u5b8c\u5168\u4e0d\u540c\uff0c\u4f46\u662f\u8fd9\u4e24\u53e5\u8bdd\u53ea\u662f\u4ea4\u6362\u4e86\"\u4f60\"\u548c\"\u6211\"\u7684\u4f4d\u7f6e\u3002 \u4e8e\u662f\u7814\u7a76\u4eba\u5458\u5f00\u59cb\u5c06\u76f8\u5bf9\u4f4d\u7f6e\u7f16\u7801\u5f15\u5165\uff0c\u76f8\u5bf9\u4f4d\u7f6e\u7f16\u7801\u7684\u4f7f\u7528\u548c\u7edd\u5bf9\u4f4d\u7f6e\u7f16\u7801\u6709\u6240\u4e0d\u540c\uff0c\u5176\u4f5c\u7528\u5728Attention\u8ba1\u7b97\u7684\u4f4d\u7f6e\uff1a $$ \\mathbf s_{ij} = \\mathbf q_i^{\\top} \\mathbf k_j/\\sqrt{d} + t_{i-j}. $$ \u5982\u679c\u5199\u6210\u77e9\u9635\u7684\u5f62\u5f0f\u5219\u66f4\u52a0\u76f4\u89c2\uff1a $$ \\begin{aligned} \\mathbf S & = \\mathbf Q \\mathbf K^{\\top} / \\sqrt {d} + \\mathbf T,\\ \\mathbf T & =\\left[\\begin{matrix} t_0 & t_{-1} & \\cdots & t_{-n+1} \\ t_1 & t_0 & & \\vdots \\ \\vdots & & t_0 & t_{-1} \\ t_{n-1} & \\ldots & t_1 & t_0 \\end{matrix}\\right] \\in \\mathbb R^{n\\times n}. \\end{aligned} $$ \u8fd9\u91cc\uff0c\u77e9\u9635$\\mathbf T$\u6709\u4e00\u4e2a\u6570\u5b66\u540d\u79f0\u2014\u2014 Toeplitz\u77e9\u9635 \uff0c\u4e0d\u96be\u770b\u51fa\u8be5\u77e9\u9635\u6709$2n-1$\u4e2a\u72ec\u7acb\u5143\u7d20\u3002","title":"\u76f8\u5bf9\u4f4d\u7f6e\u7f16\u7801"},{"location":"zh/#tnn","text":"\u6709\u4e86\u4e4b\u524d\u7684\u51c6\u5907\u5de5\u4f5c\uff0c\u53ef\u4ee5\u5f15\u5165\u6211\u4eec\u5de5\u4f5c\u7684\u4e24\u4e2a\u52a8\u673a\uff1a 1. \u65e2\u7136\u76f8\u5bf9\u4f4d\u7f6e\u4fe1\u606f\u5982\u6b64\u91cd\u8981\uff0c\u90a3\u4e48\u6709\u6ca1\u6709\u53ef\u80fd\u53ea\u4f9d\u8d56\u4e8e\u76f8\u5bf9\u4f4d\u7f6e\u4fe1\u606f\uff08Toeplitz matrix\uff09\u8fdb\u884ctoken mixing\u5462\uff1f 1. \u76f4\u89c2\u4e0a\u6765\u8bf4\uff0c\u5c31\u662f\u5c06Attention Matrix\u66ff\u6362\u4e3aToeplitz matrix\u3002 2. \u5047\u8bbe(1)\u6210\u7acb\uff0c\u90a3\u4e48\u6211\u4eec\u9700\u8981\u8fdb\u884c\u7684\u4e3b\u8981\u64cd\u4f5c\u662f$\\mathbf T \\mathbf X$\uff0c\u65e2\u7136\u77e9\u9635$\\mathbf T$\u662f\u4e00\u4e2a\u7279\u6b8a\u7ed3\u6784\u7684\u77e9\u9635\uff0c\u90a3\u4e48\u6709\u6ca1\u6709\u53ef\u80fd\u52a0\u901f\u8fd0\u7b97\u5462\uff1f \u6211\u4eec\u5bf9\u4e24\u4e2a\u95ee\u9898\u90fd\u8fdb\u884c\u4e86\u80af\u5b9a\u7684\u7b54\u590d\uff1a 1. \u5b8c\u5168\u53ef\u4ee5\u53ea\u4f9d\u8d56\u4e8e\u76f8\u5bf9\u4f4d\u7f6e\u4fe1\u606f\u8fdb\u884ctoken mixing\uff1b 2. \u7531\u4e8e\u77e9\u9635\u7684\u7279\u6b8a\u6027\uff0c\u53ef\u4ee5\u5c06\u8fd0\u7b97\u590d\u6742\u5ea6\u7531$O(n^2 d)$\u964d\u4f4e\u4e3a$O(nd\\log n)$\uff1b \u53ef\u4ee5\u770b\u5230\uff0c\u6211\u4eec\u7684\u52a8\u673a\u6781\u5176\u7b80\u5355\u548c\u4f18\u96c5\uff0c\u6700\u6838\u5fc3\u7684\u601d\u8def\u5c31\u662f\u5c06$\\mathrm{Softmax}(\\mathbf Q \\mathbf K^{\\top} / \\sqrt {d})$\u66ff\u6362\u4e3a$\\mathbf T$\uff0c\u4f46\u662f\uff0c\u8fd9\u79cd\u7b80\u5355\u7684\u66ff\u6362\u5c31\u53ef\u4ee5\u62e5\u6709\u6bd4\u5404\u79cd\u82b1\u54e8\u66f4\u6539\u66f4\u597d\u7684\u6027\u80fd\uff0c\u8fd9\u5c31\u66f4\u52a0\u9a8c\u8bc1\u4e86\u76f8\u5bf9\u4f4d\u7f6e\u4fe1\u606f\u5728\u5e8f\u5217\u5efa\u6a21\u4e2d\u7684\u91cd\u8981\u6027\u3002","title":"TNN\u7684\u52a8\u673a"},{"location":"zh/#tnn_1","text":"","title":"TNN\u7684\u5b9e\u73b0"},{"location":"zh/#_4","text":"\u63a5\u4e0b\u6765\u7684\u95ee\u9898\u5c31\u662f\u5982\u4f55\u5b9e\u73b0TNN\uff0c\u5728\u6b64\u4e4b\u524d\uff0c\u6211\u4eec\u5bf9\u4e4b\u524d\u7684\u516c\u5f0f\u505a\u4e00\u5b9a\u7684\u8c03\u6574\u3002 \u5728\u4e4b\u524d\u7684\u8ba8\u8bba\u4e2d\uff0c\u6211\u4eec\u63d0\u5230\u4e86$\\mathbf T \\mathbf X$\u53ef\u4ee5\u9ad8\u6548\u5b9e\u73b0\uff0c\u5176\u4e2d$\\mathbf T\\in \\mathbb R^{n\\times n}, \\mathbf X \\in \\mathbb R^{n\\times d}$\uff0c\u8fd9\u79cd\u60c5\u51b5\u76f8\u5f53\u4e8e\u6bcf\u4e2achannel\u5171\u4eab\u540c\u4e00\u4e2aToeplitz matrix\uff0c\u4f46\u662f\u6ce8\u610f\u5230\u6211\u4eec\u53ef\u4ee5\u8ba9\u4e0d\u540c\u7684channel\u4f7f\u7528\u4e0d\u540c\u7684Toeplitz matrix\uff0c\u6211\u4eec\u7ecf\u9a8c\u4e0a\u53d1\u73b0\uff0c\u8fd9\u6837\u4e00\u5b9a\u7a0b\u5ea6\u4e0a\u53ef\u4ee5\u589e\u5927\u6a21\u578b\u7684\u8868\u8fbe\u6027\uff0c\u6240\u4ee5\u5728TNN\u4e2d\uff0c \u6bcf\u4e2achannel \u4f7f\u7528\u4e86\u4e0d\u540c\u7684Toeplitz matrix\u3002\u6ce8\u610f\u5230\u5f62\u72b6\u4e3a$n\\times n$\u7684Toeplitz matrix\u5b9e\u9645\u4e0a\u53ea\u6709$2n-1$\u4e2a\u72ec\u7acb\u5143\u7d20\uff0c\u4e3a\u4e86\u65b9\u4fbf\u540e\u7eed\u8ba8\u8bba\uff0c\u6211\u4eec\u5b9a\u4e49\u5982\u4e0b\u6620\u5c04\uff1a$f: \\mathbb R^{(2n-1)\\times 1} \\to \\mathbb R^{n\\times n}$\uff1a $$ f(\\mathbf t)=f(t_{-n+1},\\ldots, t_{n-1}) =\\left[\\begin{matrix} t_0 & t_{-1} & \\cdots & t_{-n+1} \\ t_1 & t_0 & & \\vdots \\ \\vdots & & t_0 & t_{-1} \\ t_{n-1} & \\ldots & t_1 & t_0 \\end{matrix}\\right] \\in \\mathbb R^{n\\times n}. $$ \u8be5\u6620\u5c04\u7684\u4f5c\u7528\u662f\u5c06\u7ef4\u5ea6\u4e3a$(2n-1)\\times 1$\u7684\u5411\u91cf\u586b\u5145\u4e3a$n\\times n$\u7684Toeplitz matrix\u3002 \u7ed3\u5408\u4e4b\u524d\u7684\u8bb0\u53f7\uff0c\u6211\u4eec\u5b9a\u4e49\u4e3aTno\u7b97\u5b50(Toeplitz neural operator)\u4e3a\uff1a $$ \\mathrm{Tno}: \\mathbb R^{(2n-1)\\times d}\\times \\mathbb R^{n\\times d} \\to \\mathbb R^{n\\times d},\\ \\mathbf O= \\mathrm{Tno}(\\mathbf T, \\mathbf X), \\ \\mathbf O[:, i]= f(\\mathbf T[:, i]) \\mathbf X[:, i]. $$ \u5907\u6ce8\uff1a\u8fd9\u91cc\u7684\u8bb0\u53f7$\\mathbf T\\in \\mathbb R^{(2n-1)\\times d}$\u548c\u4e00\u5f00\u59cb\u542b\u4e49\u6709\u6240\u4e0d\u540c\uff0c\u6ce8\u610f\u4e0d\u8981\u641e\u6df7\u3002 \u5728\u5f00\u59cb\u6b63\u5f0f\u7684\u5b9e\u73b0\u4e4b\u524d\uff0c\u6211\u4eec\u5148\u5f15\u5165\u4e00\u4e9b\u5fc5\u8981\u7684\u4f9d\u8d56\u5e93\u4ee5\u53ca\u4e00\u4e9b\u8f85\u52a9\u51fd\u6570\uff1a import torch import torch.nn as nn import torch.nn.functional as F from einops import rearrange def get_activation_fn(activation): if activation == \"gelu\": return F.gelu elif activation == \"relu\": return F.relu elif activation == \"elu\": return F.elu elif activation == \"sigmoid\": return F.sigmoid elif activation == \"exp\": return torch.exp elif activation == \"leak\": return F.leaky_relu elif activation == \"1+elu\": def f(x): return 1 + F.elu(x) return f elif activation == \"2+elu\": def f(x): return 2 + F.elu(x) return f elif activation == \"silu\": return F.silu else: return lambda x: x","title":"\u51c6\u5907\u5de5\u4f5c"},{"location":"zh/#tno","text":"","title":"Tno\u7684\u5b9e\u73b0"},{"location":"zh/#naive","text":"\u6700\u6734\u7d20\u7684\u5b9e\u73b0\u81ea\u7136\u662f\u5229\u7528\u5b9a\u4e49\u8fdb\u884c\u5b9e\u73b0\uff0c\u4f8b\u5982\u5982\u4e0b\u4ee3\u7801\u4e2d\uff0c\u6211\u4eec\u4f7f\u75284\u91cd\u5faa\u73af\uff0c\u5916\u9762\u4e24\u91cd\u5faa\u73af\u904d\u5386batch, channel\u7ef4\u5ea6\uff0c\u7b2c\u4e09\u91cd\u5faa\u73af\u904d\u5386\u8f93\u51fa\u4f4d\u7f6e\uff0c\u6700\u540e\u4e00\u91cd\u5faa\u73af\u904d\u5386\u6c42\u548c\u9879\uff0c\u6ce8\u610f\u5230\u6211\u4eec\u7684$\\mathbf T[:, i]$\u8f93\u5165\u5f62\u5f0f\u4e3a$t_{-n+1}, ... , t_{-1}, t_0, t_1, ... , t_{n - 1}$\uff0c\u7b2c\u4e09\u91cd\u5faa\u73af\u904d\u5386\u5230$i$\u65f6\uff0c\u6d89\u53ca\u7684$t$\u4e3a$t_{i}, t_{i-1},\\ldots, t_{i-n+1}$\uff0c\u800c$n - 1 + i$\u662f$t_{i}$\u5728$\\mathbf T[:, i]$\u7684\u5b9e\u9645\u7d22\u5f15\uff1a def tno_naive(x, t): # x: (b, n, d) # t: (2n - 1, d), t_(-(n - 1)), ... , t_(-1), t_0, t_1, ... , t_(n - 1) b, n, d = x.shape o = torch.zeros_like(x).to(x) for b_ in range(b): for d_ in range(d): for i in range(n): for j in range(n): o[b_][i][d_] += t[n - 1 + i - j][d_] * x[b_][j][d_] return o \u8fd9\u79cd\u5b9e\u73b0\u663e\u7136\u592a\u4f4e\u6548\uff0c\u4f46\u662f\u81f3\u5c11\u6211\u4eec\u6709\u4e86\u4e00\u4e2a\u6b63\u786e\u7684\u7248\u672c\uff0c\u8fd9\u5bf9\u6211\u4eec\u540e\u7eed\u6539\u8fdb\u7b97\u6cd5\u4e5f\u662f\u6709\u5e2e\u52a9\u7684\uff0c\u4e0d\u96be\u770b\u51fa\u8fd9\u6837\u8ba1\u7b97\u7684\u65f6\u95f4\u590d\u6742\u5ea6\u4e3a$O(n^2d)$\uff0c\u7a7a\u95f4\u590d\u6742\u5ea6\u4e3a$O(nd)$\uff08\u5ffd\u7565batch\u7ef4\u5ea6\uff09\u3002","title":"Naive\u5b9e\u73b0"},{"location":"zh/#matrix-production","text":"\u7b2c\u4e8c\u79cd\u5b9e\u73b0\u662f\u5e76\u884c\u7248\u672c\uff0c\u5176\u601d\u8def\u5c31\u662f\u5148\u6784\u9020Toeplitz matrix\uff0c\u7136\u540e\u5229\u7528\u77e9\u9635\u4e58\u6cd5\u8fdb\u884c\u8ba1\u7b97\u3002\u6700\u4e3b\u8981\u7684\u90e8\u5206\u662f\u5c06\u6620\u5c04$f$\u5b9e\u73b0\u51fa\u6765\uff0c\u4ee3\u7801\u57fa\u4e8e \u6b64\u5904 \uff0c\u4e3b\u8981\u601d\u8def\u662f\u5148\u5c06\u8f93\u5165\u6539\u5199\u4e3a$t_0, t_{-1}, ... , t_{1-n}, t_{n - 1}, ... , t_1$\uff0c\u7136\u540e\u6784\u9020index $0, 1, \\ldots,n -1, -(n - 1), ..., -1$\uff0c\u5c06\u8f93\u5165\u6620\u5c04\u5230Toeplitz matrix\uff0c\u6700\u540e\u5f97\u5230Toeplitz matrix\u8fdb\u884c\u77e9\u9635\u4e58\u6cd5\uff1a def tno_matrix(x, t): # x: (b, n, d) # t: (2n - 1, d), t_(-(n - 1)), ... , t_(-1), t_0, t_1, ... , t_(n - 1) n = x.shape[1] t = t.unsqueeze(0) # c: t_0, t_1, ... , t_(n - 1) c = t[:, n - 1:] # r: t_0, t_(-1), ... , t_(-(n - 1)) r = t[:, :n].flip(1) # vals: [t_0, t_(-1), ... , t_(-(n - 1)), t_(n - 1), ... , t_1] vals = torch.cat([r, c[:, 1:].flip(1)], dim=-2) i, j = torch.ones(n, n).nonzero().T t_matrix = vals[:, j - i].reshape(n, n, -1) o = torch.einsum(\"n m d, b m d -> b n d\", t_matrix, x) return o \u8fd9\u79cd\u5b9e\u73b0\u7684\u597d\u5904\u662f\u53ef\u4ee5\u5229\u7528\u77e9\u9635\u4e58\u6cd5\uff0c\u5c3d\u7ba1\u590d\u6742\u5ea6\u4f9d\u7136\u4e3a$O(n^2d)$\uff0c\u4f46\u5b9e\u9645\u6548\u7387\u4f1a\u5feb\u5f88\u591a\uff1b\u4f46\u662f\u7531\u4e8e\u8981\u6784\u9020Toeplitz matrix\uff0c\u6240\u4ee5\u7a7a\u95f4\u590d\u6742\u5ea6\u4e3a$O(n^2d)$\uff0c\u5e76\u4e14\u8fd9\u90e8\u5206\u8fd8\u662f\u4e00\u4e2a\u5f88\u5927\u7684IO\u5f00\u9500\uff0c\u6240\u4ee5\u5b9e\u9645\u4e2d\u7684\u901f\u5ea6\u5e76\u4e0d\u4f1a\u5f88\u5feb\u3002","title":"Matrix production\u5b9e\u73b0"},{"location":"zh/#fft","text":"\u6709\u4e86\u4e4b\u524d\u7684\u94fa\u57ab\uff0c\u53ef\u4ee5\u770b\u51fa\u524d\u4e24\u79cd\u65b9\u6cd5\u65e0\u8bba\u662f\u65f6\u95f4\u590d\u6742\u5ea6\u548c\u7a7a\u95f4\u590d\u6742\u5ea6\u76f8\u6bd4Attention\u5e76\u6ca1\u6709\u4ec0\u4e48\u4f18\u52bf\uff0c\u90a3\u4e48\u6709\u6ca1\u6709\u529e\u6cd5\u89e3\u51b3\u8fd9\u70b9\u5462\uff1f\u56de\u7b54\u662f\u80af\u5b9a\u7684\uff0c\u8fd9\u5c31\u9700\u8981 FFT \u8fd9\u628a\u5229\u5203\u3002\u540e\u7eed\u7684\u8ba8\u8bba\u6d89\u53ca\u5230\u4e00\u4e9b\u6570\u5b66\u77e5\u8bc6\uff0c\u8fd9\u91cc\u5148\u9ad8\u5ea6\u6982\u62ec\u4e00\u4e0b\u601d\u8def\uff1a 1. \u7ed9\u51faCirculant matrix\u7684\u5feb\u901f\u77e9\u9635\u4e58\u6cd5\u7b97\u6cd5\uff1b 2. \u5efa\u7acbToeplitz marix\u548cCirculant matrix\u7684\u5173\u7cfb\uff1b","title":"FFT\u5b9e\u73b0"},{"location":"zh/#circulant-matrix","text":"","title":"Circulant matrix"},{"location":"zh/#_5","text":"\u77e9\u9635$\\mathbf C\\in \\mathbb R^{n\\times n}$\u662f\u4e00\u4e2a Circulant matrix \u5f53\u4e14\u4ec5\u5f53$\\mathbf C_{ij}= c_{(i-j + n )\\bmod n}$ ,\u5373\uff1a $$ \\mathbf C=\\left[\\begin{matrix} c_0 & c_{n-1} &c_{n-2} & \\cdots & \\cdots & c_{1} \\ c_1 & c_0 & c_{n-1} & \\ddots & & \\vdots \\ c_2 & c_1 & \\ddots & \\ddots & \\ddots & \\vdots \\ \\vdots & \\ddots & \\ddots & \\ddots & c_{n-1} & c_{n-2} \\ \\vdots & & \\ddots & c_1 & c_0 & c_{n-1} \\ c_{n-1} & \\ldots & \\ldots & c_2 & c_1 & c_0 \\end{matrix}\\right] \\in \\mathbb R^{n\\times n}. $$ \u5173\u4e8eCirculant matrix\uff0c\u6709\u5982\u4e0b\u91cd\u8981\u6027\u8d28\uff1a Circulant matrix $\\mathbf C\\in \\mathbb R^{n\\times n}$\u6b63\u4ea4\u76f8\u4f3c\u4e8e\u5bf9\u89d2\u9635$\\mathbf \\Lambda$\uff0c\u7279\u522b\u5730\uff0c\u76f8\u4f3c\u77e9\u9635$\\mathbf F$\u662f$n\\times n$ DFT\u77e9\u9635: $$ \\mathbf C = \\mathbf F^{\\top} \\Lambda \\mathbf F, \\ \\Lambda = \\mathrm{diag}{\\mathbf F[c_0,c_1,\\ldots, c_{n-1}]^\\top} \\in \\mathbb R^{n\\times n}, {\\mathbf F}_{st}= \\exp\\left(\\frac{2\\pi st i}{n}\\right),i^2=-1. $$ \u8bc1\u660e\u53ef\u4ee5\u53c2\u8003 \u8fd9\u91cc \u3002","title":"\u5b9a\u4e49"},{"location":"zh/#_6","text":"\u73b0\u5728\u8003\u8651matrix-vector production\u64cd\u4f5c$\\mathbf M \\mathbf x, \\mathbf M\\in \\mathbb R^{n\\times n}, \\mathbf x\\in \\mathbb R^{n\\times 1}$\uff0c\u90a3\u4e48\uff1a \u5982\u679c$\\mathbf M$\u4e3a\u4e00\u822c\u7684\u77e9\u9635\uff0c\u90a3\u4e48\u8be5\u8ba1\u7b97\u7684\u65f6\u95f4\u590d\u6742\u5ea6\u4e3a$O(n^2)$; \u5982\u679c$\\mathbf M$\u4e3aDFT\u77e9\u9635\uff0c\u90a3\u4e48\u8be5\u8ba1\u7b97\u7684\u65f6\u95f4\u590d\u6742\u5ea6\u4e3a$O(n \\log n)$; \u57fa\u4e8e\u4e0a\u8ff0\u4e8b\u5b9e\uff0c\u8003\u8651$\\mathbf M=\\mathbf C$\u4e3aCirculant matrix\u7684\u60c5\u5f62\uff0c\u90a3\u4e48\uff1a $$ \\mathbf C \\mathbf x = \\mathbf F^{\\top} \\Lambda \\mathbf F \\mathbf x. $$ \u8be5\u8ba1\u7b97\u53ef\u4ee5\u5206\u89e3\u4e3a\u51e0\u4e2a\u6b65\u9aa4\uff1a $\\mathbf x_{\\mathrm{fft}}=\\mathbf{Fx}$\uff1b $\\mathbf c_{\\mathrm{fft}}=\\mathbf F[c_0,c_1,\\ldots, c_{n-1}]^\\top$\uff1b $\\mathbf o_{\\mathrm{fft}}=\\mathbf x_{\\mathrm{fft}}\\odot \\mathbf c_{\\mathrm{fft}}$\uff1b $\\mathbf o= \\mathbf F^{\\top} \\mathbf o_{\\mathrm{fft}}$\uff1b \u5176\u4e2d$\\odot$\u8868\u793aelement-wise production\uff0c\u53ef\u4ee5\u770b\u51fa\uff0c\u7b97\u6cd5\u7684\u603b\u65f6\u95f4\u590d\u6742\u5ea6\u4e3a$O(n\\log n)$\uff0c\u7a7a\u95f4\u590d\u6742\u5ea6\u4e3a$O(n)$\uff0c\u6240\u4ee5Circulant matrix\u5bf9\u5e94\u7684\u77e9\u9635\u4e58\u6cd5\u662f\u9ad8\u6548\u7684\u3002","title":"\u5feb\u901f\u77e9\u9635\u4e58\u6cd5"},{"location":"zh/#_7","text":"\u6709\u4e86\u4e4b\u524d\u7684\u8bf4\u660e\uff0c\u4e0d\u96be\u5229\u7528 fft \u5b9e\u73b0\u4e0a\u8ff0\u8ba1\u7b97\uff1a def circulant_fft(x, c): # x: (b, n, d) # c: (n, d), c_0, c_1, ... , c_(n - 1) n = x.shape[1] c = c.unsqueeze(0) x_fft = torch.fft.rfft(x, n, dim=-2) c_fft = torch.fft.rfft(c, n, dim=-2) o_fft = x_fft * c_fft o = torch.fft.irfft(o_fft, n, dim=-2) return o","title":"\u5b9e\u73b0"},{"location":"zh/#_8","text":"\u73b0\u5728\u6211\u4eec\u5df2\u7ecf\u6709\u4e86\u4e00\u4e2a\u5173\u4e8eCirculant matrix\u7684\u9ad8\u6548\u77e9\u9635\u4e58\u6cd5\uff0c\u90a3\u4e48\u4e0b\u4e00\u4e2a\u95ee\u9898\u5c31\u662f\u5efa\u7acbToeplitz matrix\u548cCirculant matrix\u7684\u5173\u7cfb\u3002","title":"\u5c0f\u7ed3"},{"location":"zh/#toeplitz-matrix","text":"","title":"Toeplitz matrix"},{"location":"zh/#_9","text":"\u77e9\u9635$\\mathbf T\\in \\mathbb R^{n\\times n}$\u662f\u4e00\u4e2aToeplitz matrix\u5f53\u4e14\u4ec5\u5f53$\\mathbf T_{ij}= t_{i-j}$\uff0c\u5373 $$ \\mathbf T=\\left[\\begin{matrix} t_0 & t_{-1} &t_{-2} & \\cdots & \\cdots & t_{-n+1} \\ t_1 & t_0 & t_{-1} & \\ddots & & \\vdots \\ t_2 & t_1 & \\ddots & \\ddots & \\ddots & \\vdots \\ \\vdots & \\ddots & \\ddots & \\ddots & t_{-1} & t_{n-2} \\ \\vdots & & \\ddots & t_1 & t_0 & t_{-1} \\ t_{n-1} & \\ldots & \\ldots & t_2 & t_1 & t_0 \\end{matrix}\\right] \\in \\mathbb R^{n\\times n}. $$ \u4ece\u5f62\u5f0f\u4e0a\u6765\u770b\uff0cToeplitz matrix\u548cCirculant matrix\u975e\u5e38\u50cf\uff0c\u552f\u4e00\u7684\u533a\u522b\u5728\u4e8e\u524d\u8005\u7684\u72ec\u7acb\u5143\u7d20\u6570\u91cf\u4e3a$2n-1$\uff0c\u540e\u8005\u7684\u72ec\u7acb\u5143\u7d20\u6570\u91cf\u4e3a$n$\uff0c\u90a3\u4e48\u4e00\u4e2a\u7b80\u5355\u7684\u601d\u8def\u5c31\u662f\u5c06Toeplitz matrix\u5d4c\u5165\u5230\u4e00\u4e2a\u9636\u6570\u5927\u4e8e\u7b49\u4e8e$2n-1$\u77e9\u9635\u4e2d\uff0c\u800c\u8fd9\u4e2a\u77e9\u9635\u672c\u751f\u662f\u4e00\u4e2aCirculant matrix\uff0c\u4e0b\u9762\u6765\u770b\u4e0b\u8fd9\u662f\u5982\u4f55\u5177\u4f53\u64cd\u4f5c\u7684\u3002 \u53ef\u4ee5\u5c06Toeplitz matrix $\\mathbf T\\in \\mathbb R^{n\\times }$\u5d4c\u5165\u5230Circulant matrix $\\mathbf C \\in \\mathbb R^{2n\\times 2n}$\u4e2d: $$ c_{k} =\\begin{cases} t_k , 0 \\le k \\le n - 1\\ t_0 , k=n\\ t_{k -2n}, n+1\\le k \\le 2n-1 \\end{cases} , $$ \u5373\uff0c $$ \\mathbf C=\\left[\\begin{array}{ccccc|ccccc} t_0 & t_{-1} & \\ldots & \\ldots & t_{-n+1} & t_0 & t_{n-1} & \\ldots & t_2 & t_1 \\ t_1 & t_0 & \\ddots & & \\vdots & t_{-n+1} & \\ddots & \\ddots & & t_2 \\ t_2 & \\ddots & \\ddots & \\ddots & \\vdots & \\vdots & \\ddots & & \\ddots & \\vdots \\ \\vdots & & \\ddots & t_0 & t_{-1} & t_{-2} & & \\ddots & \\ddots & t_{n-1} \\ t_{n-1} & \\ldots & \\ldots & t_1 & t_0 & t_{-1} & t_{-2} & \\ldots & t_{-n+1} & t_0 \\ \\hline t_0 & t_{n-1} & \\ldots & \\ldots & t_1 & t_0 & t_{-1} & \\ldots & \\ldots & t_{-n+1} \\ t_{-n+1} & \\ddots & \\ddots & & t_2 & t_1 & t_0 & \\ddots & & \\vdots \\ \\vdots & \\ddots & & \\ddots & \\vdots & t_2 & \\ddots & \\ddots & \\ddots & \\vdots \\ t_{-2} & & \\ddots & \\ddots & t_{n-1} & \\vdots & & \\ddots & t_0 & t_{-1} \\ t_{-1} & t_{-2} & \\ldots & \\ldots & t_0 & t_{n-1} & \\ldots & \\ldots & t_1 & t_0 \\end{array}\\right] \\in \\mathbb R^{2n\\times 2n}. $$ \u4f7f\u7528\u5206\u5757\u77e9\u9635\u7684\u7b26\u53f7\uff0c\u6211\u4eec\u53ef\u4ee5\u5b9a\u4e49\uff1a $$ \\begin{gathered} \\mathbf C = \\left[\\begin{matrix} \\mathbf C_1 & \\mathbf C_2\\ \\mathbf C_3 & \\mathbf C_4\\ \\end{matrix}\\right] \\in \\mathbb R^{2n\\times 2n},\\mathbf C_s \\in \\mathbb R^{n \\times n}, s=1,2,3,4, \\mathbf C_1 = \\mathbf T \\end{gathered}. $$ \u6709\u4e86\u4e0a\u8ff0\u51c6\u5907\u5de5\u4f5c\uff0c\u53ef\u4ee5\u5f97\u5230Toeplitz matrix-vector production\u7684\u5feb\u901f\u7b97\u6cd5\u3002","title":"\u5b9a\u4e49"},{"location":"zh/#_10","text":"\u5bf9\u4e8e\u5411\u91cf$\\mathbf x\\in \\mathbb R^{n}$, \u5b9a\u4e49: $$ \\mathbf x_1 = \\left[\\begin{matrix} \\mathbf x\\ \\mathbf 0_n \\end{matrix}\\right] \\in \\mathbb R^{2n}, $$ \u6240\u4ee5\uff0c $$ \\mathbf C \\mathbf x_1 =\\left[\\begin{matrix} \\mathbf C_1 & \\mathbf C_2\\ \\mathbf C_3 & \\mathbf C_4\\ \\end{matrix}\\right]\\left[\\begin{matrix} \\mathbf x\\ \\mathbf 0_n \\end{matrix}\\right]=\\left[\\begin{matrix} \\mathbf C_1 \\mathbf x\\ \\mathbf C_3 \\mathbf x \\end{matrix}\\right]=\\left[\\begin{matrix} \\mathbf T \\mathbf x\\ \\mathbf C_3 \\mathbf x \\end{matrix}\\right] \\in \\mathbb R^{2n}, $$ \u56e0\u6b64: $$ \\left[\\begin{matrix} {\\mathbf I} n & {\\mathbf 0} {n\\times n} \\end{matrix}\\right]\\mathbf C \\mathbf x_1 = \\left[\\begin{matrix} \\mathbf I_n & \\mathbf 0_{n\\times n} \\end{matrix}\\right]\\left[\\begin{array}{c} \\mathbf T \\mathbf x\\ \\mathbf C_3 \\mathbf x \\end{array}\\right]=\\mathbf T \\mathbf x. $$ \u5173\u4e8e\u65f6\u95f4\u590d\u6742\u5ea6\uff0c\u6ce8\u610f\u5230\u6211\u4eec\u662f\u5c06$n\\times n$\u7684Toeplitz matrix\u5d4c\u5165\u5230\u4e00\u4e2a$2n\\times 2n$\u7684Circulant matrix\u4e2d\uff0c\u6240\u4ee5\u65f6\u95f4\u590d\u6742\u5ea6\u4ecd\u7136\u4e3a$O(n\\log n)$\u3002","title":"\u5feb\u901f\u77e9\u9635\u4e58\u6cd5"},{"location":"zh/#_11","text":"\u548cCirculant matrix\u7684\u60c5\u5f62\u7c7b\u4f3c\uff0c\u53ef\u4ee5\u5229\u7528 fft \u5b9e\u73b0\u4e0a\u8ff0\u8ba1\u7b97\uff1a def tno_fft(x, t): # x: (b, n, d) # t: (2 * n, d), t0, t1, ..., t(n-1), t0, t_(-(n-1)), ... , t_(-1) n = x.shape[1] t = t.unsqueeze(0) x_fft = torch.fft.rfft(x, 2 * n, dim=-2) t_fft = torch.fft.rfft(t, 2 * n, dim=-2) o_fft = x_fft * t_fft o = torch.fft.irfft(o_fft, 2 * n, dim=-2)[:, :n] return o","title":"\u5b9e\u73b0"},{"location":"zh/#_12","text":"\u5728\u4e4b\u524d\u7684\u8ba8\u8bba\u4e2d\uff0c\u6211\u4eec\u7ed9\u51fa\u4e86Tno\u7684\u4e09\u79cd\u5b9e\u73b0\u65b9\u5f0f\uff0c\u5728\u672c\u8282\u4e2d\uff0c\u6211\u4eec\u5c06\u9a8c\u8bc1\u8fd9\u4e9b\u5b9e\u73b0\u7684\u6b63\u786e\u6027\u3002 b = 2 n = 16 d = 128 t_zero = torch.randn(1, d) # t1, ..., t(n-1) t_pos = torch.randn(n - 1, d) # t-(n-1), ... , t-1 t_neg = torch.randn(n - 1, d) t1 = torch.cat([t_neg, t_zero, t_pos], dim=0).cuda() t2 = torch.cat([t_zero, t_pos, t_zero, t_neg], dim=0).cuda() x = torch.randn(b, n, d).cuda() o1 = tno_naive(x, t1) o2 = tno_matrix(x, t1) o3 = tno_fft(x, t2) print(f\"The output error between tno_naive and tno_matrix is {torch.norm(o1 - o2)}\") print(f\"The output error between tno_naive and tno_matrix is {torch.norm(o1 - o3)}\") The output error between tno_naive and tno_matrix is 2.414959999441635e-05 The output error between tno_naive and tno_matrix is 5.38119456905406e-05","title":"\u9a8c\u8bc1\u5b9e\u73b0"},{"location":"zh/#_13","text":"\u73b0\u5728\u6211\u4eec\u5df2\u7ecf\u5b8c\u6210\u4e86\u5927\u90e8\u5206\u5185\u5bb9\uff0c\u8fd9\u91cc\u6700\u540e\u8865\u5145\u5982\u4f55\u5c06Tno\u9002\u914d\u5230Autoregressive Language Model(causal)\u7684\u60c5\u5f62\u3002\u548cAttention\u7c7b\u4f3c\uff0c\u53ea\u8981\u4fdd\u8bc1Toeplitz matrix\u7684\u4e0a\u4e09\u89d2\u90e8\u5206\u4e3a$0$\u5373\u53ef\uff0c\u5373\uff1a $$ \\mathbf T=\\left[\\begin{matrix} t_0 & 0 & 0 & \\cdots & \\cdots & 0 \\ t_1 & t_0 & 0 & \\ddots & & \\vdots \\ t_2 & t_1 & \\ddots & \\ddots & \\ddots & \\vdots \\ \\vdots & \\ddots & \\ddots & \\ddots & 0 & 0 \\ \\vdots & & \\ddots & t_1 & t_0 &0 \\ t_{n-1} & \\ldots & \\ldots & t_2 & t_1 & t_0 \\end{matrix}\\right] \\in \\mathbb R^{n\\times n}. $$ \u5728\u5b9e\u73b0\u65f6\uff0c\u6ce8\u610f\u5230 fft \u662fzero padding\uff0c\u6240\u4ee5\u53ea\u9700\u8981\u5c06\u8f93\u5165\uff1a t2 = torch.cat([t_zero, t_pos, t_zero, t_neg], dim=0).cuda() \u4fee\u6539\u4e3a\u4e0b\u5f0f\u5373\u53ef\uff1a t2 = torch.cat([t_zero, t_pos, t_zero], dim=0).cuda()","title":"\u8865\u5145"},{"location":"zh/#_14","text":"\u5728\u672c\u8282\u4e2d\uff0c\u6211\u4eec\u4ecenaive\u7684\u7b97\u6cd5\u5f00\u59cb\uff0c\u6700\u7ec8\u5f97\u5230\u4e86\u4e00\u4e2a\u57fa\u4e8eFFT\u7b97\u6cd5\u7684\u9ad8\u6548\u5b9e\u73b0\uff0c\u5e76\u4e14\u7ed9\u51fa\u5904\u7406\u5355\u5411\u60c5\u5f62\u7684\u65b9\u6848\u3002","title":"\u5c0f\u7ed3"},{"location":"zh/#rpe","text":"\u6ce8\u610f\u5230Tno\u7684\u8ba1\u7b97\u6d89\u53ca\u5230$x,t$\uff0c$x$\u662f\u8f93\u5165\uff0c$t$\u662f\u76f8\u5bf9\u4f4d\u7f6e\u7cfb\u6570\uff0c\u6240\u4ee5\u4e0b\u4e00\u6b65\u5c31\u662f\u5982\u4f55\u8ba1\u7b97$t$\u3002\u5bf9\u4e8e\u5e8f\u5217\u957f\u5ea6\u4e3a$n$\uff0c\u7279\u5f81\u7ef4\u5ea6\u4e3a$d$\u7684\u6a21\u578b\uff0c\u6211\u4eec\u4e00\u5171\u6709$(2n-1)\\times d$\u4e2a\u7cfb\u6570\uff0c\u6240\u4ee5\u63a5\u4e0b\u6765\u7684\u95ee\u9898\u5c31\u662f\u5982\u4f55\u5f97\u5230\u8fd9\u4e9b\u7cfb\u6570\u3002","title":"Rpe\u7684\u5b9e\u73b0"},{"location":"zh/#naive_1","text":"\u6700\u7b80\u5355\u7684\u601d\u8def\u5c31\u662f\u76f4\u63a5\u7ed9\u6a21\u578b\u589e\u52a0$(2n-1)\\times d$\u4e2a\u53c2\u6570\uff0c\u4f46\u662f\u8fd9\u6837\u505a\u6709\u51e0\u4e2a\u95ee\u9898\uff1a 1. \u5f53\u5e8f\u5217\u957f\u5ea6$n$\u6bd4\u8f83\u5927\u7684\u65f6\u5019\uff0c\u6a21\u578b\u53c2\u6570\u91cf\u4f1a\u975e\u5e38\u591a\uff1b 2. \u5c3d\u7ba1\u6211\u4eec\u6709$(2n-1)\\times d$\u4e2a\u7cfb\u6570\uff0c\u4f46\u662f\u5bf9\u4e8e\u6bcf\u4e2achannel\u7684$2n-1$\u4e2a\u7cfb\u6570\uff0c\u4e0d\u80fd\u5b8c\u5168\u5047\u8bbe\u4ed6\u4eec\u662f\u72ec\u7acb\u7684\uff0c\u4f8b\u5982$t_1$\u548c$t_{-1}$\u5fc5\u7136\u6709\u5185\u5728\u8054\u7cfb\uff1b 3. \u65e0\u6cd5\u5904\u7406\u4efb\u610f\u957f\u7684\u5e8f\u5217\uff1b 1. \u8fd9\u70b9\u53ef\u4ee5\u7406\u89e3\u4e3a\uff0c\u5f53\u8d85\u8fc7\u6700\u5927\u5e8f\u5217\u957f\u5ea6\u65f6\uff0c\u6ca1\u6709\u5bf9\u5e94\u7684\u7cfb\u6570\uff0c\u6240\u4ee5\u6a21\u578b\u4e5f\u6ca1\u6709 \u5916\u63a8\u6027 \uff1b \u90a3\u4e48\u662f\u5426\u6709\u529e\u6cd5\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u5462\uff1f\u56de\u7b54\u662f\u80af\u5b9a\u7684\u3002","title":"Naive\u5b9e\u73b0"},{"location":"zh/#relative-position-encoder","text":"\u5bf9\u4e8e\u95ee\u9898\uff11\uff0c\uff12\uff0c\u6211\u4eec\u5229\u7528\u67d0\u79cd\u65b9\u5f0f\u53c2\u6570\u5316\u8fd9$(2n-1)\\times d$\u4e2a\u53c2\u6570\u5373\u53ef\uff0c\u6700\u7b80\u5355\u65b9\u5f0f\u5c31\u662f\u4f7f\u7528\u795e\u7ecf\u7f51\u7edc\uff0c\u7279\u522b\u7684\uff0c\u6211\u4eec\u4f7f\u7528\u7684\u662f\u4e00\u4e2a\u540d\u4e3aRelative Position Encoder(RPE)\u7684\u7f51\u7edc\uff0c\u7f51\u7edc\u7684\u8f93\u5165\u662f1\u7ef4\u5b9e\u6570$-(n-1), \\ldots, (n-1)$\uff0c\u8f93\u51fa\u662f$d$\u7ef4\u7279\u5f81\u3002\u5728\u4f7f\u7528\u65f6\uff0c\u6211\u4eec\u4f1a\u8f93\u5165$[-(n-1),\\ldots, (n-1)]^{\\top} \\in \\mathbb R^{2n-1}$\uff0c\u8f93\u51fa\u7684\u5f62\u72b6\u662f$(2n-1)\\times d$\u3002 \u5bf9\u4e8e\u95ee\u9898\uff13\uff0c\u6211\u4eec\u73b0\u5728\u53ef\u4ee5\u4e00\u5b9a\u7a0b\u5ea6\u4e0a\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u73b0\u5728\u53ea\u8981\u5c06\u76f8\u5bf9\u4f4d\u7f6e\uff08\u8d85\u51fa\u8bad\u7ec3\u65f6\u7684\u6700\u5927\u8bad\u7ec3\u957f\u5ea6\u4e5f\u53ef\uff09\u8f93\u5165\u5230RPE\u4e2d\uff0c\u5373\u53ef\u5f97\u5230\u5bf9\u5e94\u7cfb\u6570\u3002\u4f46\u662f\u8fd9\u6837\u8fd8\u8fdc\u8fdc\u4e0d\u591f\uff0c\u56e0\u4e3a\u8fd9\u79cd\u65b9\u5f0f\u53ea\u662f\u8ba9\u6a21\u578b\u201c\u5f3a\u884c\u201d\u8ba1\u7b97\u4e86\u4e00\u4e2a\u503c\uff0c\u4e3a\u4e86\u4f7f\u5f97\u6027\u80fd\u6b63\u5e38\uff0c\u6211\u4eec\u53c2\u8003\u4e86 Alibi \u7684\u65b9\u6848\uff0c\u4f7f\u7528\u4e86\u6307\u6570\u8870\u51cf\u7684\u5f62\u5f0f\uff0c\u5373\uff1a $$ \\bar t_{i-j}=\\lambda^{|i-j|} t_{i-j}, 0< \\lambda < 1. $$ \u5176\u4e2d$\\lambda$\u662f\u4e00\u4e2a\u8d85\u53c2\uff0c\u6211\u4eec\u5728$n=512$\u65f6\u9009\u62e9$\\lambda=0.99$\u3002","title":"Relative Position Encoder"},{"location":"zh/#relative-position-encoder_1","text":"\u6709\u4e86\u4e4b\u524d\u7684\u8ba8\u8bba\uff0c\u6211\u4eec\u7ed9\u51faRelative Position Encoder\u7684\u5b9e\u73b0\uff0c\u672c\u8d28\u662f\u5c31\u662f\u4e00\u4e2a\u5168\u8fde\u63a5\u7f51\u7edc\uff0c\u52a0\u4e0a\u5f52\u4e00\u5316\u548c\u6fc0\u6d3b\u51fd\u6570\uff1a class Rpe(nn.Module): def __init__( self, dim, outdim, residual, act=\"relu\", bias=True, layers=3, ): super().__init__() self.residual = residual self.outdim = outdim self.pos_dim = dim self.act = act self.pos_proj = nn.Linear(1, self.pos_dim, bias=bias) self.layers = nn.ModuleList([]) for i in range(layers): self.layers.append( nn.Sequential( nn.LayerNorm(self.pos_dim), self.get_act(), nn.Linear(self.pos_dim, self.pos_dim, bias=bias), ) ) self.out = nn.Sequential( nn.LayerNorm(self.pos_dim), self.get_act(), nn.Linear(self.pos_dim, self.outdim, bias=bias), ) def get_act(self): if self.act == \"silu\": return nn.SiLU(inplace=True) else: return nn.ReLU(inplace=True) def forward(self, biases): x = self.pos_proj(biases) if self.residual: for m in self.layers: x = m(x) + x else: for m in self.layers: x = m(x) x = self.out(x) return x","title":"\u5b9e\u73b0Relative Position Encoder"},{"location":"zh/#tnorpe","text":"\u5728\u6211\u4eec\u7684\u539f\u59cb\u5b9e\u73b0\u4e2d\uff0cRpe\u662f\u548cTno\u5408\u5e76\u5728\u4e00\u8d77\u7684\uff0c\u5b8c\u6574\u7684\u5b9e\u73b0\u5982\u4e0b\uff1a class Tno(nn.Module): def __init__( self, h, dim, rpe_dim, causal=False, use_decay=False, residual=False, act=\"relu\", par_type=1, gamma=0.99, bias=True, layers=3, ): super().__init__() self.h = h self.dim = dim self.causal = causal self.par_type = par_type self.zero_value = 0 self.use_decay = use_decay if self.use_decay: self.gamma = nn.Parameter(torch.ones(h, 1, dim) * gamma, requires_grad=False) self.rpe = Rpe( dim=rpe_dim, outdim=h * dim, residual=residual, act=act, bias=bias, layers=layers, ) if self.causal: self.forward = self.forward_causal else: self.forward = self.forward_non_causal def get_pos(self, n): if self.par_type == 1: index = torch.arange(1, 1 + n).reshape(n, -1) * 1.0 elif self.par_type == 2: index = torch.arange(1, 1 + n).reshape(n, -1) * 1.0 / n elif self.par_type == 3: index = torch.exp(torch.arange(1, 1 + n).reshape(n, -1) * 1.0 / n) return index def get_zero(self): index = torch.zeros(1).reshape(1, -1) * 1.0 if self.par_type == 3: index = torch.exp(index) return index def get_neg(self, n): if self.causal: index = torch.ones(self.h * n * self.dim).reshape(self.h, n, self.dim) * self.zero_value else: if self.par_type == 1: index = -torch.arange(1, 1 + n).flip(0).reshape(n, -1) * 1.0 elif self.par_type == 2: index = -torch.arange(1, 1 + n).flip(0).reshape(n, -1) * 1.0 / n return index def rpe_transform(self, x): # n, 1 -> n, (d * h) res = self.rpe(x) # n, (d * h) -> h, n, d res = rearrange(res, 'n (h d) -> h n d', h=self.h) return res def forward_causal(self, x, dim=-2): # x: b, h, n, d n = x.shape[dim] # a0, a1, ... , a(n-1), a0, a(-(n-1)), ... , a(-1) ##### coef # 1, d, 1 -> h, 1, d zero = self.rpe_transform(self.get_zero().to(x)) pos = self.rpe_transform(self.get_pos(n - 1).to(x)) if self.use_decay: coef = torch.arange(1, n).reshape(1, -1, 1).to(x) gamma = self.gamma gamma = gamma ** coef pos = gamma * pos a = torch.cat([zero, pos, zero], dim=1) a = self.act_fun(a) # x: b, h, n, d # a: h, l, d output = self.compute(x, a, dim, n) return output def forward_non_causal(self, x, dim=-2): # x: b, h, n, d n = x.shape[dim] # a0, a1, ... , a(n-1), a0, a(-(n-1)), ... , a(-1) ##### coef # 1, d, 1 -> h, 1, d zero = self.rpe_transform(self.get_zero().to(x)) pos = self.rpe_transform(self.get_pos(n - 1).to(x)) neg_index = self.get_neg(n - 1).to(x) if self.causal: neg = neg_index else: neg = self.rpe_transform(neg_index) if self.use_decay: coef = torch.arange(1, n).reshape(1, -1, 1).to(x) gamma = self.gamma gamma = gamma ** coef pos = gamma * pos neg = torch.flip(gamma, dims=[1]) * neg a = torch.cat([zero, pos, zero, neg], dim=1) a = self.act_fun(a) # x: b, h, n, d # a: h, l, d output = self.compute(x, a, dim, n) return output def compute(self, x, a, dim, n): # x: b, h, n, d # a: h, n, d y = torch.fft.rfft(x, 2 * n, dim=dim) v = torch.fft.rfft(a, 2 * n, dim=dim).unsqueeze(0) u = v * y output = torch.fft.irfft(u, 2 * n, dim=dim)[:, :, :n, :] return output","title":"\u5c06Tno\u548cRpe\u5408\u5e76"},{"location":"zh/#tnn-layer","text":"\u6709\u4e86\u4e4b\u524d\u7684\u94fa\u57ab\uff0c\u6211\u4eec\u53ef\u4ee5\u4ecb\u7ecdTnn Layer\uff0c\u8be5\u6a21\u5757\u5305\u542b\u4e00\u4e2aToken mixer(GTU)\u4ee5\u53ca\u4e00\u4e2aChannel mixer(GLU)\uff0c\u7531\u4e8eGLU\u548cGTU\u975e\u5e38\u76f8\u4f3c\uff0c\u6240\u4ee5\u6211\u4eec\u4eceGLU\u5f00\u59cb\u4ecb\u7ecd\u3002","title":"Tnn layer\u7684\u5b9e\u73b0"},{"location":"zh/#glu","text":"GLU \u662f\u5229\u7528Gate\u7684\u5f62\u5f0f\u8fbe\u5230Channel mixing\u7684\u4f5c\u7528\uff0c\u5199\u6210\u6570\u5b66\u516c\u5f0f\u4e3a\uff1a $$ \\mathbf O = [f({\\mathbf X} {\\mathbf W_1}) \\odot ({\\mathbf X} {\\mathbf W_2})] {\\mathbf W_3}. $$ \u5b9e\u73b0\u5982\u4e0b\uff1a class GLU(nn.Module): def __init__(self, d1, d2, act_fun, fina_act=\"None\", dropout=0.0, bias=True): super().__init__() self.l1 = nn.Linear(d1, d2, bias=bias) self.l2 = nn.Linear(d1, d2, bias=bias) self.l3 = nn.Linear(d2, d1, bias=bias) self.act_fun = get_activation_fn(act_fun) self.p = dropout if self.p > 0.0: self.dropout = nn.Dropout(p=dropout) self.fina_act = get_activation_fn(fina_act) def forward(self, x): o1 = self.l1(x) weight = self.act_fun(o1) if self.p > 0.0: weight = self.dropout(weight) o2 = self.l2(x) output = weight * o2 output = self.l3(output) output = self.fina_act(output) return output","title":"GLU"},{"location":"zh/#gtu","text":"GTU\u53c2\u8003\u4e86GLU\u7684\u601d\u8def\uff0c\u552f\u4e00\u7684\u4e0d\u540c\u662f\u5728\u5176\u4e2d\u4e00\u4e2a\u5206\u652f\u4e0a\u4f7f\u7528\u4e86 Tno \uff0c\u5e76\u4e14\u589e\u52a0\u4e00\u4e2a\u6fc0\u6d3b\u51fd\u6570\uff0c\u5199\u6210\u6570\u5b66\u516c\u5f0f\u5373\u4e3a\uff1a $$ \\mathbf O = [f({\\mathbf X} {\\mathbf W_1}) \\odot (\\mathbf T f({\\mathbf X} {\\mathbf W_2}))] {\\mathbf W_3}. $$ \u5b9e\u73b0\u5982\u4e0b\uff1a class Gtu(nn.Module): def __init__( self, embed_dim, num_heads, bias=True, act_fun=\"silu\", causal=False, expand_ratio=3, use_norm=False, norm_type=\"layernorm\", use_decay=False, rpe_layers=3, rpe_embedding=512, rpe_act=\"relu\", normalize=False, par_type=1, residual=False, gamma=0.99, ): super().__init__() self.embed_dim = embed_dim self.expand_ratio = expand_ratio self.num_heads = num_heads self.normalize = normalize d1 = int(self.expand_ratio * embed_dim) d1 = (d1 // self.num_heads) * self.num_heads self.head_dim = d1 // num_heads # linear projection self.v_proj = nn.Linear(embed_dim, d1, bias=bias) self.u_proj = nn.Linear(embed_dim, d1, bias=bias) self.o = nn.Linear(d1, embed_dim, bias=bias) self.act = get_activation_fn(act_fun) # tno self.toep = Tno( h=num_heads, dim=self.head_dim, rpe_dim=rpe_embedding, causal=causal, use_decay=use_decay, residual=residual, act=rpe_act, par_type=par_type, gamma=gamma, bias=bias, layers=rpe_layers, ) # norm self.norm_type = norm_type self.use_norm = use_norm def forward(self, x): # x: b, n, d num_heads = self.num_heads u = self.act(self.u_proj(x)) v = self.act(self.v_proj(x)) # reshape v = rearrange(v, 'b n (h d) -> b h n d', h=num_heads) output = self.toep(v, dim=-2, normalize=self.normalize) output = rearrange(output, 'b h n d -> b n (h d)') output = u * output output = self.o(output) return output","title":"GTU"},{"location":"zh/#tnnlayer","text":"\u6709\u4e86\u4e4b\u524d\u7684\u51c6\u5907\u5de5\u4f5c\uff0c\u6211\u4eec\u5f88\u5bb9\u6613\u5b9e\u73b0\u51faTnnLayer\uff0c\u56e0\u4e3a\u8fd9\u53ea\u4e0d\u8fc7\u662fGTU\u548cGLU\u7684\u5806\u53e0\uff1a class TnnLayer(nn.Module): def __init__( self, dim, num_heads, rpe_embedding, glu_dim, # model params prenorm=True, norm_type=\"layernorm\", # gtu params causal=False, gtu_act=\"silu\", expand_ratio=3, use_decay=False, gamma=0.999, # rpe params rpe_act=\"relu\", rpe_layers=3, # glu params glu_act=\"silu\", ): super().__init__() self.token_mixer = Gtu( # gtu params embed_dim=dim, num_heads=num_heads, act_fun=gtu_act, norm_type=norm_type, causal=causal, expand_ratio=expand_ratio, use_decay=use_decay, gamma=gamma, # rpe params rpe_embedding=rpe_embedding, rpe_act=rpe_act, rpe_layers=rpe_layers, ) self.token_norm = nn.LayerNorm(dim) self.feature_norm = nn.LayerNorm(dim) self.feature_mixer = GLU( d1=dim, d2=glu_dim, act_fun=glu_act, ) def forward(self, x): x = x + self.token_mixer(self.token_norm(x)) x = x + self.feature_mixer(self.feature_norm(x)) return x \u5728\u4f7f\u7528\u65f6\uff0c\u60a8\u53ea\u9700\u8981\u5c06TransformerLayer\u66ff\u6362\u6210TnnLayer\u5373\u53ef\u3002","title":"TnnLayer"},{"location":"zh/#_15","text":"\u5728\u672c\u8282\u4e2d\uff0c\u6211\u4eec\u5b8c\u6210\u4e86TnnLayer\u7684\u5b9e\u73b0\uff0c\u6709\u4e86\u4e4b\u524d\u7684\u94fa\u57ab\u5de5\u4f5c\uff0c\u8fd9\u4e00\u5207\u5e76\u4e0d\u56f0\u96be\u3002\u73b0\u5728\uff0c\u60a8\u5df2\u7ecf\u53ef\u4ee5\u5c06Tnn\u5e94\u7528\u5230\u60a8\u7684\u9879\u76ee\u4e2d\u4e86\u3002","title":"\u5c0f\u7ed3"},{"location":"zh/#_16","text":"\u901a\u8fc7\u4e4b\u524d\u7684\u5185\u5bb9\uff0c\u60a8\u5e94\u8be5\u5bf9TNN\u6709\u6240\u4e86\u89e3\uff0c\u8fd9\u91cc\uff0c\u8ba9\u6211\u4eec\u5bf9\u5168\u6587\u7684\u6838\u5fc3\u8fdb\u884c\u603b\u7ed3\uff1a Transformer\u53ef\u4ee5\u5206\u4e3aToken mixing\u548cChannel mixing\uff1b Attention\u7684\u4f5c\u7528\u662fToken mixing\uff0c\u800c\u76f8\u5bf9\u4f4d\u7f6e\u4fe1\u606f\u5bf9Attention\u5f88\u91cd\u8981\uff0c\u6211\u4eec\u63d0\u51fa\u4f7f\u7528\u76f8\u5bf9\u4f4d\u7f6e\u4fe1\u606f(Toepltiz matrix)\u6765\u4ee3\u66ffAttention Matrix\uff1b \u4f7f\u7528Toeplitz matrix\u8fdb\u884c\u77e9\u9635\u4e58\u6cd5\u53ef\u4ee5\u52a0\u901f\uff0c\u6240\u4ee5\u6211\u4eec\u7684\u65b9\u6cd5\u7406\u8bba\u4e0a\u901f\u5ea6\u5f88\u5feb\uff1b Toeplitz matrix\u7684\u7cfb\u6570\u53ef\u4ee5\u4f7f\u7528Rpe\u8fdb\u884c\u53c2\u6570\u5316\uff0c\u4ece\u800c\u51cf\u5c11\u53c2\u6570\uff0c\u7ed3\u5408\u6307\u6570\u8870\u51cf\u53ef\u4ee5\u5f97\u5230\u5916\u63a8\u6027\uff1b \u5f53\u7136\uff0cTNN\u8fd8\u6709\u5f88\u591a\u95ee\u9898\u5b58\u5728\uff0c\u4f8b\u5982\uff1a \u4e3a\u4ec0\u4e48\u76f8\u5bf9\u4f4d\u7f6e\u4fe1\u606f\u5c31\u8db3\u591f\u8fdb\u884c\u5e8f\u5217\u5efa\u6a21\uff1f TNN\u771f\u7684\u53ea\u4f7f\u7528\u4e86\u76f8\u5bf9\u4f4d\u7f6e\u4fe1\u606f\u5417\uff1f TNN\u80fd\u8fbe\u5230\u7406\u8bba\u901f\u5ea6\u4e0a\u754c\u5417\uff1f TNN\u4e0d\u80fd\u505a\u54ea\u4e9b\u4efb\u52a1\uff1f TNN\u6709\u54ea\u4e9b\u5148\u9a8c\u5047\u8bbe\uff1f \u5173\u4e8e\u8fd9\u4e9b\u95ee\u9898\uff0c\u6211\u4eec\u5c06\u5728\u540e\u7eed\u7684\u535a\u5ba2\u4e2d\u56de\u7b54\uff0c\u671f\u5f85\u60a8\u7684\u518d\u6b21\u9605\u8bfb\u3002","title":"\u5168\u6587\u603b\u7ed3"}]}